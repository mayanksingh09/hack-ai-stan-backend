This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded

Additional Info:
----------------

================================================================
Directory Structure
================================================================
app/
  models/
    __init__.py
    content.py
    platform_rules.py
  routers/
    __init__.py
    audio_transcription.py
    content_generation.py
  services/
    demo/
      ai_services.ipynb
      speech2text.ipynb
    __init__.py
    content_generator.py
    content_validator.py
    orchestrator.py
    platform_agents.py
    speech_to_text.py
    transcript_processor.py
  tests/
    __init__.py
    test_ai_services.py
    test_api_endpoints.py
    test_config.py
    test_models.py
    test_phase5_services.py
    test_platform_rules.py
  __init__.py
  config.py
  main.py
docs/
  todos/
    title_gen.md
.gitignore
LICENSE
README.md
requirements.txt

================================================================
Files
================================================================

================
File: app/models/__init__.py
================
"""
Data models for the Video Transcript to Social Media Content Generator.
Contains Pydantic models for platform rules, content generation, and API requests/responses.
"""

================
File: app/models/content.py
================
"""
Content generation models for video transcript processing and social media content output.
Defines input/output structures for the AI content generation API.
"""
from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field, field_validator, computed_field
from datetime import datetime
from .platform_rules import PlatformType


class VideoTranscript(BaseModel):
    """Input model for video transcript content."""
    
    content: str = Field(..., description="The full video transcript text", min_length=10)
    title: Optional[str] = Field(None, description="Original video title (if available)")
    duration_seconds: Optional[int] = Field(None, description="Video duration in seconds", ge=0)
    language: str = Field(default="en", description="Language code (ISO 639-1)")
    video_category: Optional[str] = Field(None, description="Video category or topic")
    metadata: Optional[Dict[str, Any]] = Field(default_factory=dict, description="Additional metadata")
    
    @field_validator('content')
    def validate_content_length(cls, v):
        """Ensure transcript content is not too short or excessively long."""
        if len(v.strip()) < 10:
            raise ValueError("Transcript content too short (minimum 10 characters)")
        if len(v) > 50000:  # ~50KB text limit
            raise ValueError("Transcript content too long (maximum 50,000 characters)")
        return v.strip()
    
    @field_validator('language')
    def validate_language_code(cls, v):
        """Basic language code validation."""
        if len(v) not in [2, 5]:  # Accept 'en' or 'en-US' format
            raise ValueError("Invalid language code format")
        return v.lower()


class GeneratedContent(BaseModel):
    """Output model for generated social media content."""
    
    title: str = Field(..., description="Generated title/caption")
    tags: List[str] = Field(..., description="Generated hashtags/tags")
    confidence_score: float = Field(..., description="AI confidence score (0-1)", ge=0, le=1)
    generation_timestamp: datetime = Field(default_factory=datetime.utcnow)
    
    @field_validator('tags')
    def validate_tags_format(cls, v):
        """Ensure tags are properly formatted."""
        cleaned_tags = []
        for tag in v:
            tag = tag.strip()
            if tag:
                # Ensure hashtag format
                if not tag.startswith('#'):
                    tag = f"#{tag}"
                # Remove spaces and special chars except underscores
                tag = ''.join(char for char in tag if char.isalnum() or char in ['#', '_'])
                if len(tag) > 1:  # Must have content after #
                    cleaned_tags.append(tag)
        return cleaned_tags
    
    @field_validator('title')
    def validate_title_not_empty(cls, v):
        """Ensure title is not empty."""
        if not v or not v.strip():
            raise ValueError("Title cannot be empty")
        return v.strip()


class PlatformContent(BaseModel):
    """Platform-specific generated content with validation against platform rules."""
    
    platform: PlatformType
    title: str
    tags: List[str]
    confidence_score: float = Field(ge=0, le=1)
    generation_timestamp: datetime = Field(default_factory=datetime.utcnow)
    meets_requirements: bool = Field(default=False, description="Whether content meets platform requirements")
    validation_notes: Optional[List[str]] = Field(default_factory=list, description="Validation notes or warnings")
    
    @computed_field
    @property
    def character_count(self) -> int:
        """Calculate character count from title."""
        return len(self.title)
    
    @computed_field
    @property
    def tag_count(self) -> int:
        """Calculate tag count from tags list."""
        return len(self.tags)
    
    def validate_against_platform_rules(self, rules) -> bool:
        """Validate content against specific platform rules."""
        validation_notes = []
        meets_requirements = True
        
        # Check title length
        if self.character_count > rules.title_max_length:
            meets_requirements = False
            validation_notes.append(f"Title exceeds maximum length ({self.character_count}/{rules.title_max_length})")
        
        # Check tag count
        if self.tag_count < rules.tag_min_count:
            meets_requirements = False
            validation_notes.append(f"Too few tags ({self.tag_count}/{rules.tag_min_count} minimum)")
        elif self.tag_count > rules.tag_max_count:
            meets_requirements = False
            validation_notes.append(f"Too many tags ({self.tag_count}/{rules.tag_max_count} maximum)")
        
        # Special case for X/Twitter - total character limit includes hashtags
        if self.platform == PlatformType.X_TWITTER:
            total_chars = len(self.title) + sum(len(tag) + 1 for tag in self.tags)  # +1 for space before each tag
            if total_chars > rules.title_max_length:
                meets_requirements = False
                validation_notes.append(f"Total content exceeds character limit ({total_chars}/{rules.title_max_length})")
        
        self.meets_requirements = meets_requirements
        self.validation_notes = validation_notes
        
        return meets_requirements


class BatchGenerationRequest(BaseModel):
    """Request model for generating content for multiple platforms."""
    
    transcript: VideoTranscript
    platforms: List[PlatformType] = Field(..., description="List of platforms to generate content for")
    options: Optional[Dict[str, Any]] = Field(default_factory=dict, description="Generation options")
    
    @field_validator('platforms')
    def validate_platforms_not_empty(cls, v):
        """Ensure at least one platform is specified."""
        if not v:
            raise ValueError("At least one platform must be specified")
        return list(set(v))  # Remove duplicates


class BatchGenerationResponse(BaseModel):
    """Response model for batch content generation."""
    
    request_id: str = Field(..., description="Unique request identifier")
    generated_content: Dict[str, PlatformContent] = Field(..., description="Generated content by platform")
    processing_time_seconds: float = Field(..., description="Total processing time")
    success_count: int = Field(..., description="Number of successful generations")
    error_count: int = Field(..., description="Number of failed generations")
    errors: Optional[Dict[str, str]] = Field(default_factory=dict, description="Errors by platform")
    
    @field_validator('generated_content')
    def validate_content_keys(cls, v):
        """Ensure all keys are valid platform types."""
        for platform_key in v.keys():
            if platform_key not in [p.value for p in PlatformType]:
                raise ValueError(f"Invalid platform key: {platform_key}")
        return v


class ContentGenerationOptions(BaseModel):
    """Options for content generation customization."""
    
    tone: Optional[str] = Field(default="neutral", description="Content tone (casual, professional, energetic, etc.)")
    include_emojis: bool = Field(default=True, description="Whether to include emojis in generated content")
    target_audience: Optional[str] = Field(None, description="Target audience description")
    keywords_to_include: Optional[List[str]] = Field(default_factory=list, description="Specific keywords to include")
    keywords_to_avoid: Optional[List[str]] = Field(default_factory=list, description="Keywords to avoid")
    brand_voice: Optional[str] = Field(None, description="Brand voice guidelines")
    custom_instructions: Optional[str] = Field(None, description="Additional custom instructions for AI")

================
File: app/models/platform_rules.py
================
"""
Platform-specific rules and configuration models for social media content generation.
Defines character limits, tag requirements, and content style guidelines for each platform.
"""
from typing import List, Optional
from pydantic import BaseModel, Field, ConfigDict
from enum import Enum


class ContentStyle(str, Enum):
    """Content style categories for different platforms."""
    EDUCATIONAL_ENTERTAINMENT = "educational_entertainment"
    VISUAL_LIFESTYLE = "visual_lifestyle"
    COMMUNITY_BUILDING = "community_building"
    TREND_FOCUSED = "trend_focused"
    PROFESSIONAL = "professional"
    GAMING_COMMUNITY = "gaming_community"
    CONCISE_TIMELY = "concise_timely"


class PlatformType(str, Enum):
    """Supported social media platforms."""
    YOUTUBE = "youtube"
    INSTAGRAM = "instagram"
    FACEBOOK = "facebook"
    TIKTOK = "tiktok"
    X_TWITTER = "x_twitter"
    LINKEDIN = "linkedin"
    TWITCH = "twitch"


class PlatformRules(BaseModel):
    """Base model for platform-specific content generation rules."""
    
    platform: PlatformType
    title_max_length: int
    tag_min_count: int
    tag_max_count: int
    content_style: ContentStyle
    style_guidelines: List[str]
    special_requirements: Optional[List[str]] = None
    
    model_config = ConfigDict(use_enum_values=True)


class YouTubeRules(PlatformRules):
    """Content rules for YouTube platform."""
    
    def __init__(self, **data):
        super().__init__(
            platform=PlatformType.YOUTUBE,
            title_max_length=100,
            tag_min_count=10,
            tag_max_count=15,
            content_style=ContentStyle.EDUCATIONAL_ENTERTAINMENT,
            style_guidelines=[
                "Engaging and SEO-friendly titles",
                "Balance educational and entertainment value",
                "Use trending keywords for discoverability",
                "Clear, descriptive content that matches video topic"
            ],
            special_requirements=[
                "Focus on trending keywords",
                "Optimize for YouTube search algorithm",
                "Consider video thumbnail compatibility"
            ],
            **data
        )


class InstagramRules(PlatformRules):
    """Content rules for Instagram platform."""
    
    def __init__(self, **data):
        super().__init__(
            platform=PlatformType.INSTAGRAM,
            title_max_length=150,
            tag_min_count=20,
            tag_max_count=30,
            content_style=ContentStyle.VISUAL_LIFESTYLE,
            style_guidelines=[
                "Visually appealing and lifestyle-focused",
                "Use mix of popular and niche hashtags",
                "Encourage engagement and interaction",
                "Visual-first content approach"
            ],
            special_requirements=[
                "Hashtag-heavy approach (20-30 tags)",
                "Mix trending and niche hashtags",
                "Consider Instagram Reels format"
            ],
            **data
        )


class FacebookRules(PlatformRules):
    """Content rules for Facebook platform."""
    
    def __init__(self, **data):
        super().__init__(
            platform=PlatformType.FACEBOOK,
            title_max_length=255,
            tag_min_count=3,
            tag_max_count=5,
            content_style=ContentStyle.COMMUNITY_BUILDING,
            style_guidelines=[
                "Engagement-focused and shareable",
                "Community-building approach",
                "Moderate hashtag usage",
                "Encourage comments and shares"
            ],
            special_requirements=[
                "Not hashtag-heavy (3-5 only)",
                "Focus on shareability",
                "Encourage community interaction"
            ],
            **data
        )


class TikTokRules(PlatformRules):
    """Content rules for TikTok platform."""
    
    def __init__(self, **data):
        super().__init__(
            platform=PlatformType.TIKTOK,
            title_max_length=150,
            tag_min_count=3,
            tag_max_count=5,
            content_style=ContentStyle.TREND_FOCUSED,
            style_guidelines=[
                "Trend-aware and catchy",
                "Gen-Z friendly language",
                "Viral potential focus",
                "Current trend integration"
            ],
            special_requirements=[
                "Use trending hashtags",
                "Consider current TikTok trends",
                "Appeal to younger demographics"
            ],
            **data
        )


class XTwitterRules(PlatformRules):
    """Content rules for X (Twitter) platform."""
    
    def __init__(self, **data):
        super().__init__(
            platform=PlatformType.X_TWITTER,
            title_max_length=280,  # Total character limit including hashtags
            tag_min_count=2,
            tag_max_count=3,
            content_style=ContentStyle.CONCISE_TIMELY,
            style_guidelines=[
                "Concise and timely",
                "Conversation-starting",
                "Hashtags integrated into text",
                "Current events awareness"
            ],
            special_requirements=[
                "280 character total limit (including hashtags)",
                "Hashtags integrated into main text",
                "Focus on current conversations"
            ],
            **data
        )


class LinkedInRules(PlatformRules):
    """Content rules for LinkedIn platform."""
    
    def __init__(self, **data):
        super().__init__(
            platform=PlatformType.LINKEDIN,
            title_max_length=210,
            tag_min_count=3,
            tag_max_count=5,
            content_style=ContentStyle.PROFESSIONAL,
            style_guidelines=[
                "Professional and thought-leadership focused",
                "Industry-relevant content",
                "Professional networking approach",
                "Value-driven messaging"
            ],
            special_requirements=[
                "Professional tone mandatory",
                "Industry-specific hashtags",
                "Thought leadership angle"
            ],
            **data
        )


class TwitchRules(PlatformRules):
    """Content rules for Twitch platform."""
    
    def __init__(self, **data):
        super().__init__(
            platform=PlatformType.TWITCH,
            title_max_length=140,
            tag_min_count=3,
            tag_max_count=8,
            content_style=ContentStyle.GAMING_COMMUNITY,
            style_guidelines=[
                "Gaming and streaming focused",
                "Community-oriented",
                "Interactive content emphasis",
                "Gaming terminology usage"
            ],
            special_requirements=[
                "Gaming categories focus",
                "Community interaction emphasis",
                "Streaming-specific language"
            ],
            **data
        )


# Platform rules instances
PLATFORM_RULES = {
    PlatformType.YOUTUBE: YouTubeRules(),
    PlatformType.INSTAGRAM: InstagramRules(),
    PlatformType.FACEBOOK: FacebookRules(),
    PlatformType.TIKTOK: TikTokRules(),
    PlatformType.X_TWITTER: XTwitterRules(),
    PlatformType.LINKEDIN: LinkedInRules(),
    PlatformType.TWITCH: TwitchRules(),
}


def get_platform_rules(platform: PlatformType) -> PlatformRules:
    """Get rules for a specific platform."""
    return PLATFORM_RULES[platform]


def get_all_platforms() -> List[PlatformType]:
    """Get list of all supported platforms."""
    return list(PlatformType)

================
File: app/routers/__init__.py
================
"""
FastAPI routers for the Video Transcript to Social Media Content Generator.
Contains API endpoint definitions for content generation and platform information.
"""

================
File: app/routers/audio_transcription.py
================
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from services.speech_to_text import get_transcription

router = APIRouter(prefix="/api/v1", tags=["audio-transcription"])

# Request schema for the transcription endpoint
class TranscriptionRequest(BaseModel):
    audio_url: str
    model_id: str = "scribe_v1"
    language_code: str = "eng"
    diarize: bool = True
    tag_audio_events: bool = True

@router.post("/transcribe")
async def get_transcript(request: TranscriptionRequest):

    try:
        # get_transcription is a synchronous function, so we call it directly (without await)
        transcription = get_transcription(
            audio_url=request.audio_url,
            model_id=request.model_id,
            language_code=request.language_code,
            diarize=request.diarize,
            tag_audio_events=request.tag_audio_events,
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    
    return transcription

================
File: app/routers/content_generation.py
================
"""
API endpoints for content generation - simplified version.
"""
from fastapi import APIRouter, HTTPException
from typing import Dict, Any
import time
import logging

import sys
from pathlib import Path

# Add parent directory to path for imports
parent_dir = Path(__file__).parent.parent
sys.path.insert(0, str(parent_dir))

from models.platform_rules import PlatformType, get_platform_rules
from models.content import VideoTranscript, PlatformContent
from services.orchestrator import get_content_orchestrator
from services.content_validator import ContentValidator

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/api/v1", tags=["content-generation"])


# Simple request model
from pydantic import BaseModel

class GenerateContentRequest(BaseModel):
    """Request model for content generation."""
    transcript: VideoTranscript


@router.get("/platforms")
async def get_supported_platforms():
    """Get list of all supported platforms with their basic information."""
    platforms = {}
    
    for platform in PlatformType:
        rules = get_platform_rules(platform)
        platforms[platform.value] = {
            "name": platform.value.replace("_", " ").title(),
            "title_max_length": rules.title_max_length,
            "tag_range": f"{rules.tag_min_count}-{rules.tag_max_count}",
            "style": rules.content_style
        }
    
    return {
        "platforms": platforms,
        "total_supported": len(platforms)
    }


@router.get("/platforms/{platform}/rules")
async def get_platform_rules_endpoint(platform: str):
    """Get detailed rules and guidelines for a specific platform."""
    try:
        platform_type = PlatformType(platform)
    except ValueError:
        raise HTTPException(status_code=404, detail=f"Platform '{platform}' not supported")
    
    rules = get_platform_rules(platform_type)
    
    return {
        "platform": platform,
        "rules": {
            "title_max_length": rules.title_max_length,
            "tag_min_count": rules.tag_min_count,
            "tag_max_count": rules.tag_max_count,
            "content_style": rules.content_style,
            "style_guidelines": rules.style_guidelines
        },
        "special_requirements": rules.special_requirements if rules.special_requirements else []
    }


@router.post("/generate/{platform}")
async def generate_content_for_platform(platform: str, request: GenerateContentRequest):
    """Generate content for a specific platform from a video transcript."""
    start_time = time.time()
    
    # Validate platform
    try:
        platform_type = PlatformType(platform)
    except ValueError:
        raise HTTPException(status_code=404, detail=f"Platform '{platform}' not supported")
    
    # Get orchestrator and generate content
    orchestrator = get_content_orchestrator()
    
    try:
        # Generate content with simplified orchestrator
        content = await orchestrator.generate_content(platform_type, request.transcript)
        
        # Validate the generated content
        validator = ContentValidator()
        validation_result = validator.validate_content(content)
        
        processing_time = time.time() - start_time
        
        return {
            "platform": platform,
            "content": content.model_dump(),
            "validation_passed": validation_result.is_valid,
            "quality_score": validation_result.score,
            "issues": [
                {"field": issue.field, "message": issue.message}
                for issue in validation_result.issues
            ] if validation_result.issues else [],
            "processing_time_seconds": round(processing_time, 2)
        }
        
    except Exception as e:
        logger.error(f"Content generation failed for {platform}: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"Content generation failed: {str(e)}"
        )


@router.post("/validate/{platform}")
async def validate_content(platform: str, content: PlatformContent):
    """Validate existing content against platform rules."""
    # Validate platform
    try:
        platform_type = PlatformType(platform)
    except ValueError:
        raise HTTPException(status_code=404, detail=f"Platform '{platform}' not supported")
    
    # Check platform match
    if content.platform != platform_type:
        raise HTTPException(
            status_code=400,
            detail=f"Content platform '{content.platform.value}' doesn't match endpoint platform '{platform}'"
        )
    
    # Validate content
    validator = ContentValidator()
    validation_result = validator.validate_content(content)
    suggestions = validator.suggest_improvements(validation_result)
    
    return {
        "platform": platform,
        "is_valid": validation_result.is_valid,
        "quality_score": validation_result.score,
        "issues": [
            {
                "severity": issue.severity.value,
                "field": issue.field,
                "message": issue.message
            }
            for issue in validation_result.issues
        ],
        "suggestions": suggestions
    }


@router.get("/health")
async def health_check():
    """Check if the content generation service is healthy."""
    try:
        # Simple health check
        orchestrator = get_content_orchestrator()
        
        return {
            "status": "healthy",
            "services": {
                "orchestrator": "active",
                "validator": "active"
            },
            "supported_platforms": [p.value for p in PlatformType]
        }
        
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        raise HTTPException(status_code=503, detail="Service unhealthy")

================
File: app/services/demo/ai_services.ipynb
================
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "# Add python_services to the path\n",
    "python_services_dir = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "sys.path.insert(0, python_services_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.platform_rules import PlatformType\n",
    "from models.content import VideoTranscript, PlatformContent\n",
    "from services.transcript_processor import TranscriptProcessor, TranscriptAnalysis\n",
    "from services.platform_agents import PlatformAgentManager, get_platform_agent_manager\n",
    "from services.content_generator import ContentGeneratorService, ContentGenerationRequest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:services.content_generator:AI service initialized with model: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "transcript = VideoTranscript(\n",
    "    content=\"This is a test video about artificial intelligence and machine learning.\",\n",
    "    title=\"AI Tutorial\",\n",
    "    video_category=\"technology\"\n",
    ")\n",
    "service = ContentGeneratorService()\n",
    "\n",
    "prompt = service._build_platform_prompt(\n",
    "    PlatformType.YOUTUBE, transcript, \"energetic\", True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackai",
   "language": "python",
   "name": "hackai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

================
File: app/services/demo/speech2text.ipynb
================
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language_code='eng' language_probability=1.0 text=\"Hi. Thank you for being part of AdviceHub. It's a platform that connects top AI and technology experts with clients looking for their expertise. Today, I'll be walking you through how you can sign up as an expert on the platform. So first, head on over to advicehub.ai. If you haven't already signed up as a user, please go ahead and click on Sign In, and you can sign up to create an account. The easiest way would be to use Google or LinkedIn, but you can also use your email. It's going to send you a verification email that you can click on and then it would redirect you to the website. So let's go ahead and use Google for now. I'm going to be using my AdviceHub email. So after you've signed in, you can click on the Expert Sign-Up page, and now fill out this form. So going ahead and picking up an image. I highly recommend uploading an image because that's going to be used on your expert profile that's shown on the screen. So I'm going to keep it brief for the demo, but please be as descriptive as possible for this. (silence) And just like that, they would send us a verification email for us to verify your profile. And once that's done, um, so it's typically within 24 to 48 hours, like it mentions here, you can go ahead and see your profile on the platform. So let's go ahead and do that. Yeah. And once we approve it, you should be able to see your profile on the platform. Please write to us if you see any issues with the sign-up flow or if you have any questions. Thank you so much.\" words=[SpeechToTextWordResponseModel(text='Hi.', start=2.039, end=2.299, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=2.299, end=3.439, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='Thank', start=3.439, end=3.599, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=3.599, end=3.619, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='you', start=3.619, end=3.679, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=3.679, end=3.699, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='for', start=3.699, end=3.839, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=3.839, end=3.859, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='being', start=3.859, end=4.0, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=4.0, end=4.099, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='part', start=4.099, end=4.259, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=4.259, end=4.259, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='of', start=4.259, end=4.339, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=4.339, end=4.38, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='AdviceHub.', start=4.38, end=5.08, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=5.08, end=5.279, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=\"It's\", start=5.279, end=5.42, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=5.42, end=5.44, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='a', start=5.44, end=5.48, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=5.48, end=5.5, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='platform', start=5.5, end=5.799, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=5.799, end=5.799, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='that', start=5.799, end=5.94, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=5.94, end=5.94, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='connects', start=5.94, end=6.239, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=6.239, end=6.239, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='top', start=6.239, end=6.499, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=6.499, end=6.539, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='AI', start=6.539, end=6.779, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=6.779, end=6.799, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='and', start=6.799, end=6.859, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=6.859, end=6.899, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='technology', start=6.899, end=7.339, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=7.339, end=7.379, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='experts', start=7.379, end=7.779, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=7.779, end=7.839, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='with', start=7.839, end=7.98, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=7.98, end=8.079, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='clients', start=8.079, end=8.46, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=8.46, end=8.46, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='looking', start=8.46, end=8.719, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=8.719, end=8.739, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='for', start=8.739, end=8.8, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=8.8, end=8.819, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='their', start=8.819, end=8.98, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=8.98, end=9.0, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='expertise.', start=9.0, end=9.699, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=9.699, end=10.199, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='Today,', start=10.199, end=10.439, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=10.439, end=10.439, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=\"I'll\", start=10.439, end=10.579, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=10.579, end=10.579, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='be', start=10.579, end=10.68, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=10.68, end=10.699, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='walking', start=10.699, end=10.979, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=10.979, end=11.019, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='you', start=11.019, end=11.119, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=11.119, end=11.219, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='through', start=11.219, end=11.519, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=11.519, end=11.92, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='how', start=11.92, end=12.119, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=12.119, end=12.179, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='you', start=12.179, end=12.239, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=12.239, end=12.259, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='can', start=12.259, end=12.36, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=12.36, end=12.439, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='sign', start=12.439, end=12.659, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=12.659, end=12.679, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='up', start=12.679, end=12.779, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=12.779, end=12.779, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='as', start=12.779, end=12.899, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=12.899, end=12.899, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='an', start=12.899, end=12.98, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=12.98, end=13.0, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='expert', start=13.0, end=13.319, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=13.319, end=13.359, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='on', start=13.359, end=13.439, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=13.439, end=13.439, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='the', start=13.439, end=13.5, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=13.5, end=13.539, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='platform.', start=13.539, end=14.06, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=14.06, end=15.139, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='So', start=15.139, end=15.219, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=15.219, end=15.259, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='first,', start=15.259, end=15.479, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=15.479, end=15.5, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='head', start=15.5, end=15.619, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=15.619, end=15.659, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='on', start=15.659, end=15.76, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=15.76, end=15.779, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='over', start=15.779, end=15.96, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=15.96, end=15.979, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='to', start=15.979, end=16.06, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=16.06, end=16.079, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='advicehub.ai.', start=16.079, end=17.259, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=17.259, end=18.059, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='If', start=18.059, end=18.139, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=18.139, end=18.159, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='you', start=18.159, end=18.219, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=18.219, end=18.239, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=\"haven't\", start=18.239, end=18.439, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=18.439, end=18.459, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='already', start=18.459, end=18.719, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=18.719, end=18.739, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='signed', start=18.739, end=19.04, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=19.04, end=19.059, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='up', start=19.059, end=19.18, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=19.18, end=19.199, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='as', start=19.199, end=19.299, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=19.299, end=19.319, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='a', start=19.319, end=19.379, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=19.379, end=19.459, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='user,', start=19.459, end=19.819, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=19.819, end=19.939, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='please', start=19.939, end=20.139, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=20.139, end=20.159, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='go', start=20.159, end=20.26, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=20.26, end=20.299, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='ahead', start=20.299, end=20.479, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=20.479, end=20.5, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='and', start=20.5, end=20.6, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=20.6, end=20.719, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='click', start=20.719, end=20.879, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=20.879, end=20.899, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='on', start=20.899, end=20.979, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=20.979, end=21.02, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='Sign', start=21.02, end=21.28, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=21.28, end=21.319, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='In,', start=21.319, end=21.539, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=21.539, end=21.68, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='and', start=21.68, end=21.879, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=21.879, end=21.92, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='you', start=21.92, end=21.96, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=21.96, end=21.979, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='can', start=21.979, end=22.079, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=22.079, end=22.119, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='sign', start=22.119, end=22.319, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=22.319, end=22.359, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='up', start=22.359, end=22.539, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=22.539, end=23.059, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='to', start=23.059, end=23.18, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=23.18, end=23.219, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='create', start=23.219, end=23.399, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=23.399, end=23.42, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='an', start=23.42, end=23.499, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=23.499, end=23.539, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='account.', start=23.539, end=23.879, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=23.879, end=24.5, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='The', start=24.5, end=24.599, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=24.599, end=24.659, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='easiest', start=24.659, end=24.979, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=24.979, end=25.0, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='way', start=25.0, end=25.139, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=25.139, end=25.139, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='would', start=25.139, end=25.299, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=25.299, end=25.319, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='be', start=25.319, end=25.42, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=25.42, end=25.459, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='to', start=25.459, end=25.619, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=25.619, end=25.68, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='use', start=25.68, end=25.899, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=25.899, end=26.0, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='Google', start=26.0, end=26.26, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=26.26, end=26.26, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='or', start=26.26, end=26.36, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=26.36, end=26.399, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='LinkedIn,', start=26.399, end=26.879, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=26.879, end=26.92, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='but', start=26.92, end=27.019, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=27.019, end=27.039, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='you', start=27.039, end=27.1, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=27.1, end=27.119, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='can', start=27.119, end=27.199, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=27.199, end=27.199, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='also', start=27.199, end=27.439, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=27.439, end=27.479, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='use', start=27.479, end=27.659, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=27.659, end=27.68, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='your', start=27.68, end=27.819, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=27.819, end=27.859, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='email.', start=27.859, end=28.219, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=28.219, end=28.239, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=\"It's\", start=28.239, end=28.36, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=28.36, end=28.379, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='going', start=28.379, end=28.5, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=28.5, end=28.539, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='to', start=28.539, end=28.599, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=28.599, end=28.639, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='send', start=28.639, end=28.819, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=28.819, end=28.859, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='you', start=28.859, end=28.959, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=28.959, end=28.959, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='a', start=28.959, end=29.039, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=29.039, end=29.039, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='verification', start=29.039, end=29.559, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=29.559, end=29.619, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='email', start=29.619, end=29.92, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=29.92, end=30.559, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='that', start=30.559, end=30.879, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=30.879, end=30.939, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='you', start=30.939, end=31.019, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=31.019, end=31.039, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='can', start=31.039, end=31.159, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=31.159, end=31.179, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='click', start=31.179, end=31.34, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=31.34, end=31.359, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='on', start=31.359, end=31.519, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=31.519, end=31.539, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='and', start=31.539, end=31.659, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=31.659, end=31.679, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='then', start=31.679, end=31.78, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=31.78, end=31.799, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='it', start=31.799, end=31.88, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=31.88, end=31.899, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='would', start=31.899, end=32.059, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=32.059, end=32.059, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='redirect', start=32.059, end=32.439, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=32.439, end=32.459, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='you', start=32.459, end=32.56, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=32.56, end=32.579, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='to', start=32.579, end=32.659, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=32.659, end=32.68, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='the', start=32.68, end=32.74, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=32.74, end=32.759, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='website.', start=32.759, end=33.219, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=33.219, end=33.659, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='So', start=33.659, end=33.74, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=33.74, end=33.759, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=\"let's\", start=33.759, end=33.92, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=33.92, end=33.939, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='go', start=33.939, end=34.04, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=34.04, end=34.059, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='ahead', start=34.059, end=34.2, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=34.2, end=34.219, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='and', start=34.219, end=34.279, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=34.279, end=34.319, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='use', start=34.319, end=34.479, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=34.479, end=34.52, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='Google', start=34.52, end=34.759, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=34.759, end=34.779, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='for', start=34.779, end=34.9, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=34.9, end=34.919, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='now.', start=34.919, end=35.159, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=35.159, end=35.159, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=\"I'm\", start=35.159, end=35.319, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=35.319, end=35.34, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='going', start=35.34, end=35.52, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=35.52, end=35.54, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='to', start=35.54, end=35.619, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=35.619, end=35.659, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='be', start=35.659, end=35.72, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=35.72, end=35.779, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='using', start=35.779, end=36.0, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=36.0, end=36.02, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='my', start=36.02, end=36.119, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=36.119, end=36.139, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='AdviceHub', start=36.139, end=36.679, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=36.679, end=36.719, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='email.', start=36.719, end=37.159, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=37.159, end=39.04, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='So', start=39.04, end=39.239, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=39.239, end=39.279, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='after', start=39.279, end=39.52, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=39.52, end=39.54, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=\"you've\", start=39.54, end=39.659, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=39.659, end=39.719, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='signed', start=39.719, end=39.979, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=39.979, end=40.02, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='in,', start=40.02, end=40.28, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=40.28, end=40.599, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='you', start=40.599, end=40.68, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=40.68, end=40.7, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='can', start=40.7, end=40.799, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=40.799, end=40.84, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='click', start=40.84, end=41.02, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=41.02, end=41.04, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='on', start=41.04, end=41.139, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=41.139, end=41.159, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='the', start=41.159, end=41.22, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=41.22, end=41.279, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='Expert', start=41.279, end=41.62, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=41.62, end=41.7, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='Sign-Up', start=41.7, end=42.04, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=42.04, end=42.099, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='page,', start=42.099, end=42.539, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=42.539, end=43.34, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='and', start=43.34, end=43.5, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=43.5, end=43.559, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='now', start=43.559, end=43.7, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=43.7, end=43.739, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='fill', start=43.739, end=43.92, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=43.92, end=43.939, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='out', start=43.939, end=44.06, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=44.06, end=44.099, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='this', start=44.099, end=44.279, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=44.279, end=44.319, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='form.', start=44.319, end=44.679, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=44.679, end=45.079, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='So', start=45.079, end=45.36, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=45.36, end=46.259, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='going', start=46.259, end=46.52, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=46.52, end=46.559, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='ahead', start=46.559, end=46.819, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=46.819, end=46.84, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='and', start=46.84, end=46.959, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=46.959, end=47.02, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='picking', start=47.02, end=47.279, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=47.279, end=47.299, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='up', start=47.299, end=47.459, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=47.459, end=47.739, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='an', start=47.739, end=47.799, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=47.799, end=47.86, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='image.', start=47.86, end=48.22, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=48.22, end=48.239, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='I', start=48.239, end=48.299, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=48.299, end=48.299, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='highly', start=48.299, end=48.56, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=48.56, end=48.599, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='recommend', start=48.599, end=48.879, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=48.879, end=48.879, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='uploading', start=48.879, end=49.2, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=49.2, end=49.219, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='an', start=49.219, end=49.279, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=49.279, end=49.299, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='image', start=49.299, end=49.52, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=49.52, end=49.539, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='because', start=49.539, end=49.799, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=49.799, end=49.819, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=\"that's\", start=49.819, end=50.02, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=50.02, end=50.039, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='going', start=50.039, end=50.2, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=50.2, end=50.2, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='to', start=50.2, end=50.259, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=50.259, end=50.299, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='be', start=50.299, end=50.38, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=50.38, end=50.459, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='used', start=50.459, end=50.779, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=50.779, end=51.259, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='on', start=51.259, end=51.36, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=51.36, end=51.379, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='your', start=51.379, end=51.459, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=51.459, end=51.5, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='expert', start=51.5, end=51.799, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=51.799, end=51.819, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='profile', start=51.819, end=52.2, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=52.2, end=52.379, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=\"that's\", start=52.379, end=52.639, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=52.639, end=52.68, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='shown', start=52.68, end=52.959, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=52.959, end=53.0, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='on', start=53.0, end=53.139, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=53.139, end=53.18, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='the', start=53.18, end=53.259, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=53.259, end=53.299, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='screen.', start=53.299, end=53.619, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=53.619, end=55.259, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='So', start=55.259, end=55.459, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=55.459, end=55.52, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=\"I'm\", start=55.52, end=55.639, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=55.639, end=55.659, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='going', start=55.659, end=55.819, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=55.819, end=55.819, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='to', start=55.819, end=55.84, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=55.84, end=55.879, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='keep', start=55.879, end=56.0, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=56.0, end=56.02, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='it', start=56.02, end=56.099, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=56.099, end=56.139, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='brief', start=56.139, end=56.399, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=56.399, end=56.399, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='for', start=56.399, end=56.56, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=56.56, end=56.579, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='the', start=56.579, end=56.7, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=56.7, end=56.759, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='demo,', start=56.759, end=57.159, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=57.159, end=57.199, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='but', start=57.199, end=57.359, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=57.359, end=57.419, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='please', start=57.419, end=57.679, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=57.679, end=57.739, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='be', start=57.739, end=58.119, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=58.119, end=58.18, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='as', start=58.18, end=58.34, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=58.34, end=58.359, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='descriptive', start=58.359, end=58.799, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=58.799, end=58.819, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='as', start=58.819, end=58.939, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=58.939, end=59.099, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='possible', start=59.099, end=59.599, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=59.599, end=60.079, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='for', start=60.079, end=60.24, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=60.24, end=60.279, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='this.', start=60.279, end=60.719, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=60.719, end=68.239, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='(silence)', start=68.239, end=148.919, type='audio_event', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=148.919, end=149.02, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='And', start=149.02, end=149.139, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=149.139, end=149.179, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='just', start=149.179, end=149.319, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=149.319, end=149.379, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='like', start=149.379, end=149.559, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=149.559, end=149.599, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='that,', start=149.599, end=149.819, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=149.819, end=150.119, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='they', start=150.119, end=150.239, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=150.239, end=150.259, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='would', start=150.259, end=150.44, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=150.44, end=150.459, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='send', start=150.459, end=150.739, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=150.739, end=151.479, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='us', start=151.479, end=151.619, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=151.619, end=151.66, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='a', start=151.66, end=151.72, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=151.72, end=151.739, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='verification', start=151.739, end=152.38, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=152.38, end=152.44, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='email', start=152.44, end=152.8, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=152.8, end=153.119, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='for', start=153.119, end=153.279, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=153.279, end=153.319, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='us', start=153.319, end=153.419, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=153.419, end=153.44, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='to', start=153.44, end=153.519, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=153.519, end=153.539, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='verify', start=153.539, end=153.879, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=153.879, end=153.879, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='your', start=153.879, end=154.019, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=154.019, end=154.039, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='profile.', start=154.039, end=154.54, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=154.54, end=155.479, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='And', start=155.479, end=155.619, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=155.619, end=155.66, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='once', start=155.66, end=155.899, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=155.899, end=155.94, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=\"that's\", start=155.94, end=156.199, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=156.199, end=156.239, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='done,', start=156.239, end=156.519, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=156.519, end=156.86, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='um,', start=156.86, end=157.179, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=157.179, end=157.699, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='so', start=157.699, end=157.74, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=157.74, end=157.74, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=\"it's\", start=157.74, end=157.86, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=157.86, end=157.86, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='typically', start=157.86, end=158.24, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=158.24, end=158.259, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='within', start=158.259, end=158.579, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=158.579, end=158.599, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='24', start=158.599, end=159.039, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=159.039, end=159.059, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='to', start=159.059, end=159.279, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=159.279, end=159.519, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='48', start=159.519, end=159.899, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=159.899, end=159.899, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='hours,', start=159.899, end=160.199, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=160.199, end=160.339, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='like', start=160.339, end=160.479, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=160.479, end=160.479, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='it', start=160.479, end=160.58, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=160.58, end=160.58, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='mentions', start=160.58, end=160.979, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=160.979, end=160.979, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='here,', start=160.979, end=161.239, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=161.239, end=162.94, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='you', start=162.94, end=163.019, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=163.019, end=163.039, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='can', start=163.039, end=163.16, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=163.16, end=163.179, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='go', start=163.179, end=163.319, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=163.319, end=163.36, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='ahead', start=163.36, end=163.579, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=163.579, end=163.599, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='and', start=163.599, end=163.72, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=163.72, end=163.739, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='see', start=163.739, end=163.879, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=163.879, end=163.899, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='your', start=163.899, end=163.979, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=163.979, end=164.019, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='profile', start=164.019, end=164.479, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=164.479, end=164.539, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='on', start=164.539, end=164.679, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=164.679, end=164.699, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='the', start=164.699, end=164.759, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=164.759, end=164.819, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='platform.', start=164.819, end=165.399, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=165.399, end=165.399, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='So', start=165.399, end=165.66, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=165.66, end=166.459, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=\"let's\", start=166.459, end=166.66, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=166.66, end=166.699, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='go', start=166.699, end=166.819, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=166.819, end=166.86, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='ahead', start=166.86, end=167.059, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=167.059, end=167.08, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='and', start=167.08, end=167.199, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=167.199, end=167.199, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='do', start=167.199, end=167.36, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=167.36, end=167.399, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='that.', start=167.399, end=167.739, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=167.739, end=174.759, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='Yeah.', start=174.759, end=175.859, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=175.859, end=175.86, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='And', start=175.86, end=175.96, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=175.96, end=175.979, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='once', start=175.979, end=176.139, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=176.139, end=176.16, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='we', start=176.16, end=176.239, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=176.239, end=176.239, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='approve', start=176.239, end=176.539, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=176.539, end=176.559, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='it,', start=176.559, end=176.699, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=176.699, end=176.739, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='you', start=176.739, end=176.819, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=176.819, end=176.819, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='should', start=176.819, end=176.939, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=176.939, end=176.959, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='be', start=176.959, end=177.019, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=177.019, end=177.039, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='able', start=177.039, end=177.199, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=177.199, end=177.22, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='to', start=177.22, end=177.32, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=177.32, end=177.36, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='see', start=177.36, end=177.5, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=177.5, end=177.839, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='your', start=177.839, end=177.959, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=177.959, end=177.979, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='profile', start=177.979, end=178.36, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=178.36, end=178.399, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='on', start=178.399, end=178.5, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=178.5, end=178.519, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='the', start=178.519, end=178.579, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=178.579, end=178.619, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='platform.', start=178.619, end=179.159, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=179.159, end=179.639, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='Please', start=179.639, end=179.879, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=179.879, end=179.899, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='write', start=179.899, end=180.139, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=180.139, end=180.159, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='to', start=180.159, end=180.259, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=180.259, end=180.3, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='us', start=180.3, end=180.58, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=180.58, end=180.619, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='if', start=180.619, end=180.819, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=180.819, end=180.86, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='you', start=180.86, end=181.419, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=181.419, end=181.459, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='see', start=181.459, end=181.619, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=181.619, end=181.619, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='any', start=181.619, end=181.839, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=181.839, end=181.879, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='issues', start=181.879, end=182.679, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=182.679, end=182.679, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='with', start=182.679, end=182.839, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=182.839, end=182.839, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='the', start=182.839, end=182.979, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=182.979, end=182.979, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='sign-up', start=182.979, end=183.38, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=183.38, end=183.419, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='flow', start=183.419, end=183.66, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=183.66, end=184.039, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='or', start=184.039, end=184.259, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=184.259, end=184.259, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='if', start=184.259, end=184.38, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=184.38, end=184.399, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='you', start=184.399, end=184.459, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=184.459, end=184.479, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='have', start=184.479, end=184.58, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=184.58, end=184.599, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='any', start=184.599, end=184.739, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=184.739, end=184.759, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='questions.', start=184.759, end=185.259, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=185.259, end=185.739, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='Thank', start=185.739, end=185.919, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=185.919, end=185.94, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='you', start=185.94, end=186.019, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=186.019, end=186.019, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='so', start=186.019, end=186.119, type='word', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text=' ', start=186.119, end=186.179, type='spacing', speaker_id='speaker_0', logprob=0.0, characters=None), SpeechToTextWordResponseModel(text='much.', start=186.179, end=186.519, type='word', speaker_id='speaker_0', logprob=0.0, characters=None)] additional_formats=None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from elevenlabs.client import ElevenLabs\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "elevenlabs = ElevenLabs(\n",
    "  api_key=os.getenv(\"ELEVEN_LABS_API_KEY\"),\n",
    ")\n",
    "\n",
    "audio_url = (\n",
    "    \"https://taqijvfimwhlcgbodvhk.supabase.co/storage/v1/object/public/hack-ai-public-storage-bucket/videos/How%20to%20Sign%20Up%20as%20an%20Expert%20on%20AdviceHub.mp4\"\n",
    ")\n",
    "response = requests.get(audio_url)\n",
    "audio_data = BytesIO(response.content)\n",
    "\n",
    "transcription = elevenlabs.speech_to_text.convert(\n",
    "    file=audio_data,\n",
    "    model_id=\"scribe_v1\", # Model to use, for now only \"scribe_v1\" is supported\n",
    "    tag_audio_events=True, # Tag audio events like laughter, applause, etc.\n",
    "    language_code=\"eng\", # Language of the audio file. If set to None, the model will detect the language automatically.\n",
    "    diarize=True, # Whether to annotate who is speaking\n",
    ")\n",
    "\n",
    "print(transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi. Thank you for being part of AdviceHub. It's a platform that connects top AI and technology experts with clients looking for their expertise. Today, I'll be walking you through how you can sign up as an expert on the platform. So first, head on over to advicehub.ai. If you haven't already signed up as a user, please go ahead and click on Sign In, and you can sign up to create an account. The easiest way would be to use Google or LinkedIn, but you can also use your email. It's going to send you a verification email that you can click on and then it would redirect you to the website. So let's go ahead and use Google for now. I'm going to be using my AdviceHub email. So after you've signed in, you can click on the Expert Sign-Up page, and now fill out this form. So going ahead and picking up an image. Highly recommend uploading an image because that's going to be used on your expert profile that's shown on the screen. So I'm gonna keep it brief for the demo, but please be as descriptive as possible for this. (silence) And just like that, they would send us a verification email for us to verify your profile. And once that's done, um, it's typically within 24 to 48 hours, like it mentions here, you can go ahead and see your profile on the platform. So let's go ahead and do that. Yeah. And once we approve it, you should be able to see your profile on the platform. Please write to us if you see any issues with the sign-up flow or if you have any questions. Thank you so much.\n"
     ]
    }
   ],
   "source": [
    "print(transcription.model_dump()['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackai",
   "language": "python",
   "name": "hackai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

================
File: app/services/__init__.py
================
"""
Business logic services for the Video Transcript to Social Media Content Generator.
Contains AI content generation, transcript processing, and orchestration services.
"""

================
File: app/services/content_generator.py
================
"""
Base AI Content Generation Service using Pydantic AI and OpenAI.
Provides core functionality for generating social media content from video transcripts.
"""
from typing import List, Dict, Optional, Any
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
from pydantic_ai.providers.openai import OpenAIProvider
from pydantic import BaseModel, Field
import asyncio
import logging
from datetime import datetime

import sys
from pathlib import Path

# Add parent directory to path for imports
parent_dir = Path(__file__).parent.parent
sys.path.insert(0, str(parent_dir))

from config import settings
from models.platform_rules import PlatformType, get_platform_rules
from models.content import VideoTranscript, PlatformContent, GeneratedContent

# Configure logging
logging.basicConfig(level=getattr(logging, settings.log_level.upper()))
logger = logging.getLogger(__name__)


class ContentGenerationRequest(BaseModel):
    """Request model for content generation."""
    transcript: VideoTranscript
    platform: PlatformType
    additional_context: Optional[str] = None
    tone: Optional[str] = "neutral"
    include_emojis: bool = True


class ContentGeneratorService:
    """Base AI service for generating social media content from video transcripts."""
    
    def __init__(self, model_name: str = "gpt-4o"):
        """Initialize the content generator service."""
        self.model_name = model_name
        self.model = None
        self.agent = None
        self._initialize_ai_service()
    
    def _initialize_ai_service(self):
        """Initialize the Pydantic AI service with OpenAI."""
        try:
            # Create OpenAI model with provider
            provider = OpenAIProvider(api_key=settings.openai_api_key)
            self.model = OpenAIModel(self.model_name, provider=provider)
            
            # Create AI agent with base system prompt
            self.agent = Agent(
                model=self.model,
                system_prompt=self._get_base_system_prompt()
            )
            
            logger.info(f"AI service initialized with model: {self.model_name}")
            
        except Exception as e:
            logger.error(f"Failed to initialize AI service: {e}")
            raise
    
    def _get_base_system_prompt(self) -> str:
        """Get the base system prompt for content generation."""
        return """You are an expert social media content creator and marketing specialist. 
Your job is to analyze video transcripts and generate engaging, platform-appropriate titles and hashtags.

Key principles:
1. Always match the platform's specific style and requirements
2. Create engaging, clickable titles that capture the essence of the content
3. Use relevant, trending hashtags that will increase discoverability
4. Maintain authenticity while optimizing for engagement
5. Consider the target audience for each platform

You will be provided with:
- Video transcript content
- Target platform specifications
- Platform-specific rules and constraints
- Optional tone and style preferences

Generate content that:
- Meets all platform character limits and tag counts
- Reflects the actual content of the video
- Uses appropriate tone for the platform
- Maximizes engagement potential
- Follows current social media best practices

Always return your response in the exact JSON format requested, with proper title and tags arrays."""
    
    def _build_platform_prompt(self, platform: PlatformType, transcript: VideoTranscript, 
                             tone: str = "neutral", include_emojis: bool = True) -> str:
        """Build platform-specific prompt for content generation."""
        rules = get_platform_rules(platform)
        
        platform_context = {
            PlatformType.YOUTUBE: "YouTube audience expects educational, entertaining content with SEO-optimized titles",
            PlatformType.INSTAGRAM: "Instagram users love visual, lifestyle-focused content with plenty of hashtags",
            PlatformType.FACEBOOK: "Facebook prioritizes community engagement and shareable content",
            PlatformType.TIKTOK: "TikTok thrives on trendy, viral content that appeals to Gen-Z",
            PlatformType.X_TWITTER: "X/Twitter users want concise, timely content that sparks conversation",
            PlatformType.LINKEDIN: "LinkedIn requires professional, industry-focused, thought-leadership content",
            PlatformType.TWITCH: "Twitch focuses on gaming, streaming, and interactive community content"
        }
        
        emoji_instruction = "Include relevant emojis to enhance engagement" if include_emojis else "Do not include emojis"
        
        prompt = f"""
PLATFORM: {platform.value.upper()}
PLATFORM CONTEXT: {platform_context[platform]}

PLATFORM REQUIREMENTS:
- Maximum title length: {rules.title_max_length} characters
- Required tags: {rules.tag_min_count}-{rules.tag_max_count} hashtags
    - Content style: {str(rules.content_style).replace('_', ' ').title()}
- Style guidelines: {', '.join(rules.style_guidelines)}

CONTENT TONE: {tone}
EMOJI USAGE: {emoji_instruction}

VIDEO TRANSCRIPT:
"{transcript.content}"

ADDITIONAL CONTEXT:
- Original title: {transcript.title or 'Not provided'}
- Video category: {transcript.video_category or 'General'}
- Duration: {transcript.duration_seconds or 'Unknown'} seconds
- Language: {transcript.language}

Generate a {platform.value} post with:
1. An engaging title/caption that captures the video's essence
2. Relevant hashtags that will maximize discoverability
3. Content that follows {platform.value} best practices

CRITICAL: Ensure the title does not exceed {rules.title_max_length} characters and you provide exactly {rules.tag_min_count}-{rules.tag_max_count} hashtags.

Respond with a JSON object in this exact format:
{{
    "title": "your generated title here",
    "tags": ["#hashtag1", "#hashtag2", "#hashtag3"],
    "confidence": 0.85
}}
"""
        return prompt
    
    async def generate_content(self, request: ContentGenerationRequest) -> PlatformContent:
        """Generate platform-specific content from video transcript."""
        if not self.agent:
            raise RuntimeError("AI service not properly initialized")
        
        try:
            # Build platform-specific prompt
            prompt = self._build_platform_prompt(
                platform=request.platform,
                transcript=request.transcript,
                tone=request.tone,
                include_emojis=request.include_emojis
            )
            
            # Generate content using AI
            logger.info(f"Generating content for {request.platform.value}")
            result = await self.agent.run(prompt)
            
            # Parse AI response
            ai_response = result.output
            
            # Handle both string and dict responses
            if isinstance(ai_response, str):
                import json
                try:
                    ai_response = json.loads(ai_response)
                except json.JSONDecodeError:
                    # Fallback parsing if JSON is malformed
                    ai_response = self._parse_fallback_response(ai_response)
            
            # Create platform content
            content = PlatformContent(
                platform=request.platform,
                title=ai_response.get("title", "Generated Title"),
                tags=ai_response.get("tags", ["#content"]),
                confidence_score=float(ai_response.get("confidence", 0.7))
            )
            
            # Validate against platform rules
            rules = get_platform_rules(request.platform)
            content.validate_against_platform_rules(rules)
            
            logger.info(f"Content generated successfully for {request.platform.value}")
            return content
            
        except Exception as e:
            logger.error(f"Content generation failed for {request.platform.value}: {e}")
            raise
    
    def _parse_fallback_response(self, response_text: str) -> Dict[str, Any]:
        """Fallback parsing when JSON response is malformed."""
        # Simple regex-based extraction as fallback
        import re
        
        title_match = re.search(r'"title":\s*"([^"]*)"', response_text)
        tags_match = re.search(r'"tags":\s*\[(.*?)\]', response_text)
        confidence_match = re.search(r'"confidence":\s*([0-9.]+)', response_text)
        
        title = title_match.group(1) if title_match else "Generated Content"
        
        tags = []
        if tags_match:
            tags_str = tags_match.group(1)
            tags = [tag.strip(' "') for tag in tags_str.split(',')]
            tags = [tag if tag.startswith('#') else f"#{tag}" for tag in tags if tag]
        
        confidence = float(confidence_match.group(1)) if confidence_match else 0.7
        
        return {
            "title": title,
            "tags": tags or ["#content"],
            "confidence": confidence
        }
    
    def generate_content_sync(self, request: ContentGenerationRequest) -> PlatformContent:
        """Synchronous wrapper for content generation."""
        try:
            # Use run_sync method for synchronous execution
            if not self.agent:
                raise RuntimeError("AI service not properly initialized")
            
            # Build platform-specific prompt
            prompt = self._build_platform_prompt(
                platform=request.platform,
                transcript=request.transcript,
                tone=request.tone,
                include_emojis=request.include_emojis
            )
            
            # Generate content using AI synchronously
            logger.info(f"Generating content for {request.platform.value} (sync)")
            result = self.agent.run_sync(prompt)
            
            # Parse AI response
            ai_response = result.output
            
            # Handle both string and dict responses
            if isinstance(ai_response, str):
                import json
                try:
                    ai_response = json.loads(ai_response)
                except json.JSONDecodeError:
                    # Fallback parsing if JSON is malformed
                    ai_response = self._parse_fallback_response(ai_response)
            
            # Create platform content
            content = PlatformContent(
                platform=request.platform,
                title=ai_response.get("title", "Generated Title"),
                tags=ai_response.get("tags", ["#content"]),
                confidence_score=float(ai_response.get("confidence", 0.7))
            )
            
            # Validate against platform rules
            rules = get_platform_rules(request.platform)
            content.validate_against_platform_rules(rules)
            
            logger.info(f"Content generated successfully for {request.platform.value} (sync)")
            return content
            
        except Exception as e:
            logger.error(f"Sync content generation failed for {request.platform.value}: {e}")
            raise
    
    async def test_connection(self) -> bool:
        """Test the AI service connection."""
        try:
            if not self.agent:
                return False
                
            test_prompt = "Respond with exactly: 'AI service is working correctly'"
            result = await self.agent.run(test_prompt)
            
            return "working correctly" in str(result.output).lower()
            
        except Exception as e:
            logger.error(f"AI service connection test failed: {e}")
            return False
    
    def test_connection_sync(self) -> bool:
        """Synchronous test of AI service connection."""
        try:
            if not self.agent:
                return False
                
            test_prompt = "Respond with exactly: 'AI service is working correctly'"
            result = self.agent.run_sync(test_prompt)
            
            return "working correctly" in str(result.output).lower()
            
        except Exception as e:
            logger.error(f"Sync AI service connection test failed: {e}")
            return False


# Global service instance
_content_generator_service = None


def get_content_generator() -> ContentGeneratorService:
    """Get global content generator service instance."""
    global _content_generator_service
    if _content_generator_service is None:
        _content_generator_service = ContentGeneratorService()
    return _content_generator_service

================
File: app/services/content_validator.py
================
"""
Content Validation Service for validating generated content against platform rules
and providing fallback content generation for failed validations.
"""
import logging
from typing import List, Dict, Optional, Tuple, Any
from dataclasses import dataclass
from enum import Enum

import sys
from pathlib import Path

# Add parent directory to path for imports
parent_dir = Path(__file__).parent.parent
sys.path.insert(0, str(parent_dir))

from models.platform_rules import PlatformType, get_platform_rules, PlatformRules
from models.content import VideoTranscript, PlatformContent, ContentGenerationOptions

logger = logging.getLogger(__name__)


class ValidationSeverity(str, Enum):
    """Severity levels for validation issues."""
    ERROR = "error"      # Must be fixed - content unusable
    WARNING = "warning"  # Should be fixed - content may underperform
    INFO = "info"       # Nice to fix - minor optimization


@dataclass
class ValidationIssue:
    """Represents a validation issue found in content."""
    field: str
    severity: ValidationSeverity
    message: str
    current_value: Any | None = None
    expected_value: Optional[Any] = None
    suggestion: Optional[str] = None


@dataclass
class ValidationResult:
    """Result of content validation."""
    is_valid: bool
    score: float  # 0-100, quality score
    issues: List[ValidationIssue]
    platform: PlatformType
    content: PlatformContent


class ContentValidator:
    """Service for validating generated content against platform rules and quality standards."""
    
    def __init__(self):
        self.quality_weights = {
            "character_limit": 0.3,
            "tag_count": 0.25,
            "content_quality": 0.2,
            "platform_style": 0.15,
            "engagement_potential": 0.1
        }
    
    def validate_content(self, content: PlatformContent, 
                        strict_mode: bool = True) -> ValidationResult:
        """Validate content against platform rules and quality standards."""
        rules = get_platform_rules(content.platform)
        issues = []
        
        # Validate character limits
        char_issues = self._validate_character_limits(content, rules)
        issues.extend(char_issues)
        
        # Validate tag count
        tag_issues = self._validate_tag_count(content, rules)
        issues.extend(tag_issues)
        
        # Validate content quality
        quality_issues = self._validate_content_quality(content, rules)
        issues.extend(quality_issues)
        
        # Validate platform-specific requirements
        platform_issues = self._validate_platform_specific(content, rules)
        issues.extend(platform_issues)
        
        # Calculate overall validity
        error_count = len([issue for issue in issues if issue.severity == ValidationSeverity.ERROR])
        is_valid = error_count == 0 if strict_mode else error_count <= 1
        
        # Calculate quality score
        score = self._calculate_quality_score(content, rules, issues)
        
        return ValidationResult(
            is_valid=is_valid,
            score=score,
            issues=issues,
            platform=content.platform,
            content=content
        )
    
    def _validate_character_limits(self, content: PlatformContent, 
                                 rules: PlatformRules) -> List[ValidationIssue]:
        """Validate character limits for the platform."""
        issues = []
        
        # Title character limit
        if content.character_count > rules.title_max_length:
            issues.append(ValidationIssue(
                field="title",
                severity=ValidationSeverity.ERROR,
                message=f"Title exceeds maximum length",
                current_value=content.character_count,
                expected_value=rules.title_max_length,
                suggestion=f"Reduce title to {rules.title_max_length} characters or less"
            ))
        elif content.character_count > rules.title_max_length * 0.9:
            issues.append(ValidationIssue(
                field="title",
                severity=ValidationSeverity.WARNING,
                message="Title is very close to character limit",
                current_value=content.character_count,
                expected_value=rules.title_max_length,
                suggestion="Consider shortening for better display"
            ))
        
        # Special case for X/Twitter total character limit
        if content.platform == PlatformType.X_TWITTER:
            total_chars = len(content.title) + sum(len(tag) + 1 for tag in content.tags)
            if total_chars > rules.title_max_length:
                issues.append(ValidationIssue(
                    field="total_content",
                    severity=ValidationSeverity.ERROR,
                    message="Total content (title + hashtags) exceeds character limit",
                    current_value=total_chars,
                    expected_value=rules.title_max_length,
                    suggestion="Reduce title length or number of hashtags"
                ))
        
        return issues
    
    def _validate_tag_count(self, content: PlatformContent, 
                          rules: PlatformRules) -> List[ValidationIssue]:
        """Validate hashtag/tag count for the platform."""
        issues = []
        
        if content.tag_count < rules.tag_min_count:
            issues.append(ValidationIssue(
                field="tags",
                severity=ValidationSeverity.ERROR,
                message=f"Too few tags",
                current_value=content.tag_count,
                expected_value=f"{rules.tag_min_count}-{rules.tag_max_count}",
                suggestion=f"Add {rules.tag_min_count - content.tag_count} more relevant tags"
            ))
        elif content.tag_count > rules.tag_max_count:
            issues.append(ValidationIssue(
                field="tags",
                severity=ValidationSeverity.ERROR,
                message=f"Too many tags",
                current_value=content.tag_count,
                expected_value=f"{rules.tag_min_count}-{rules.tag_max_count}",
                suggestion=f"Remove {content.tag_count - rules.tag_max_count} tags"
            ))
        
        return issues
    
    def _validate_content_quality(self, content: PlatformContent, 
                                rules: PlatformRules) -> List[ValidationIssue]:
        """Validate content quality and engagement potential."""
        issues = []
        
        # Check for empty or very short titles
        if len(content.title.strip()) < 10:
            issues.append(ValidationIssue(
                field="title",
                severity=ValidationSeverity.ERROR,
                message="Title too short to be engaging",
                current_value=len(content.title.strip()),
                expected_value="10+ characters",
                suggestion="Create a more descriptive, engaging title"
            ))
        
        # Check for repetitive hashtags
        unique_tags = set(tag.lower() for tag in content.tags)
        if len(unique_tags) < len(content.tags):
            issues.append(ValidationIssue(
                field="tags",
                severity=ValidationSeverity.WARNING,
                message="Duplicate hashtags detected",
                current_value=len(content.tags),
                expected_value=len(unique_tags),
                suggestion="Remove duplicate hashtags for better reach"
            ))
        
        # Check hashtag formatting
        malformed_tags = [tag for tag in content.tags if not tag.startswith('#') or len(tag) <= 1]
        if malformed_tags:
            issues.append(ValidationIssue(
                field="tags",
                severity=ValidationSeverity.ERROR,
                message="Malformed hashtags detected",
                current_value=malformed_tags,
                suggestion="Ensure all tags start with # and have content"
            ))
        
        # Check for low confidence score
        if content.confidence_score < 0.6:
            issues.append(ValidationIssue(
                field="confidence",
                severity=ValidationSeverity.WARNING,
                message="Low AI confidence in generated content",
                current_value=content.confidence_score,
                expected_value="0.6+",
                suggestion="Consider regenerating content for better quality"
            ))
        
        return issues
    
    def _validate_platform_specific(self, content: PlatformContent, 
                                  rules: PlatformRules) -> List[ValidationIssue]:
        """Validate platform-specific requirements."""
        issues = []
        
        # Platform-specific validation rules
        if content.platform == PlatformType.LINKEDIN:
            # Check for professional tone
            casual_indicators = ['hey', 'guys', 'lol', 'omg', 'awesome', 'epic']
            title_lower = content.title.lower()
            found_casual = [word for word in casual_indicators if word in title_lower]
            if found_casual:
                issues.append(ValidationIssue(
                    field="tone",
                    severity=ValidationSeverity.WARNING,
                    message="Content may be too casual for LinkedIn",
                    current_value=found_casual,
                    suggestion="Use more professional language"
                ))
        
        elif content.platform == PlatformType.TIKTOK:
            # Check for trend awareness
            if not any(tag.lower() in ['#fyp', '#viral', '#trending'] for tag in content.tags):
                issues.append(ValidationIssue(
                    field="tags",
                    severity=ValidationSeverity.INFO,
                    message="Consider adding trending TikTok hashtags",
                    suggestion="Add #fyp, #viral, or #trending for better reach"
                ))
        
        elif content.platform == PlatformType.INSTAGRAM:
            # Check for emoji usage (Instagram prefers visual elements)
            if '😀' not in content.title and '🎯' not in content.title and not any(char in content.title for char in '✨🌟💫🔥💯'):
                issues.append(ValidationIssue(
                    field="visual_appeal",
                    severity=ValidationSeverity.INFO,
                    message="Consider adding emojis for better visual appeal",
                    suggestion="Add relevant emojis to increase engagement"
                ))
        
        return issues
    
    def _calculate_quality_score(self, content: PlatformContent, rules: PlatformRules, 
                               issues: List[ValidationIssue]) -> float:
        """Calculate quality score (0-100) based on content and validation issues."""
        base_score = 100.0
        
        # Deduct points for issues
        for issue in issues:
            if issue.severity == ValidationSeverity.ERROR:
                base_score -= 25
            elif issue.severity == ValidationSeverity.WARNING:
                base_score -= 10
            elif issue.severity == ValidationSeverity.INFO:
                base_score -= 5
        
        # Bonus points for good practices
        
        # Character limit utilization (sweet spot: 70-90% of limit)
        char_utilization = content.character_count / rules.title_max_length
        if 0.7 <= char_utilization <= 0.9:
            base_score += 5
        
        # Tag count optimization
        tag_range = rules.tag_max_count - rules.tag_min_count
        if tag_range > 0:
            optimal_tags = rules.tag_min_count + (tag_range * 0.7)  # 70% of range
            if abs(content.tag_count - optimal_tags) <= 2:
                base_score += 5
        
        # Confidence score bonus
        if content.confidence_score >= 0.8:
            base_score += 5
        elif content.confidence_score >= 0.9:
            base_score += 10
        
        return max(0.0, min(100.0, base_score))
    
    def suggest_improvements(self, validation_result: ValidationResult) -> List[str]:
        """Generate improvement suggestions based on validation results."""
        suggestions = []
        
        for issue in validation_result.issues:
            if issue.suggestion:
                suggestions.append(f"{issue.field.title()}: {issue.suggestion}")
        
        # General quality improvements
        if validation_result.score < 80:
            suggestions.append("Consider regenerating content for higher quality")
        
        if validation_result.content.confidence_score < 0.7:
            suggestions.append("Low AI confidence - try different tone or keywords")
        
        return suggestions
    
    def create_fallback_content(self, platform: PlatformType, transcript: VideoTranscript,
                              original_validation: ValidationResult) -> PlatformContent:
        """Create fallback content when original content fails validation."""
        rules = get_platform_rules(platform)
        
        # Analyze issues to create better content
        char_issues = [issue for issue in original_validation.issues 
                      if issue.field == "title" and "character" in issue.message.lower()]
        tag_issues = [issue for issue in original_validation.issues 
                     if issue.field == "tags"]
        
        # Create simplified, rule-compliant content
        fallback_title = self._create_fallback_title(transcript, rules, char_issues)
        fallback_tags = self._create_fallback_tags(transcript, rules, tag_issues)
        
        fallback_content = PlatformContent(
            platform=platform,
            title=fallback_title,
            tags=fallback_tags,
            confidence_score=0.6  # Lower confidence for fallback
        )
        
        # Validate fallback content
        fallback_validation = self.validate_content(fallback_content, strict_mode=False)
        
        if fallback_validation.is_valid:
            logger.info(f"Fallback content created for {platform.value}")
            return fallback_content
        else:
            logger.warning(f"Fallback content also failed validation for {platform.value}")
            return self._create_minimal_content(platform, transcript)
    
    def _create_fallback_title(self, transcript: VideoTranscript, rules: PlatformRules,
                             char_issues: List[ValidationIssue]) -> str:
        """Create a safe fallback title."""
        base_title = transcript.title or "Video Content"
        
        # If title is too long, truncate intelligently
        if char_issues and rules.title_max_length:
            max_len = rules.title_max_length - 3  # Leave space for "..."
            if len(base_title) > max_len:
                # Try to cut at word boundary
                words = base_title.split()
                truncated = ""
                for word in words:
                    if len(truncated + word + " ") <= max_len:
                        truncated += word + " "
                    else:
                        break
                base_title = truncated.strip() + "..."
        
        return base_title[:rules.title_max_length] if rules.title_max_length else base_title
    
    def _create_fallback_tags(self, transcript: VideoTranscript, rules: PlatformRules,
                            tag_issues: List[ValidationIssue]) -> List[str]:
        """Create safe fallback tags."""
        # Extract basic keywords from transcript
        words = transcript.content.lower().split()
        common_words = {'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}
        keywords = [word for word in words if len(word) > 3 and word not in common_words]
        
        # Get unique keywords
        unique_keywords = list(set(keywords))[:rules.tag_max_count]
        
        # Ensure we have enough tags
        tags = [f"#{keyword}" for keyword in unique_keywords]
        
        # Fill up to minimum if needed
        while len(tags) < rules.tag_min_count:
            generic_tags = ["#content", "#video", "#social", "#media", "#digital"]
            for tag in generic_tags:
                if tag not in tags and len(tags) < rules.tag_min_count:
                    tags.append(tag)
        
        return tags[:rules.tag_max_count]
    
    def _create_minimal_content(self, platform: PlatformType, transcript: VideoTranscript) -> PlatformContent:
        """Create minimal viable content as last resort."""
        rules = get_platform_rules(platform)
        
        minimal_title = "Video Content"[:rules.title_max_length]
        minimal_tags = ["#content"]
        
        # Add minimum required tags
        while len(minimal_tags) < rules.tag_min_count:
            minimal_tags.append(f"#tag{len(minimal_tags)}")
        
        return PlatformContent(
            platform=platform,
            title=minimal_title,
            tags=minimal_tags[:rules.tag_max_count],
            confidence_score=0.3  # Very low confidence for minimal content
        )


# Global validator instance
_content_validator = None


def get_content_validator() -> ContentValidator:
    """Get global content validator instance."""
    global _content_validator
    if _content_validator is None:
        _content_validator = ContentValidator()
    return _content_validator

================
File: app/services/orchestrator.py
================
"""
Simplified Content Generation Orchestrator for creating platform-specific content.
"""
import logging
from typing import Optional
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel

import sys
from pathlib import Path

# Add parent directory to path for imports
parent_dir = Path(__file__).parent.parent
sys.path.insert(0, str(parent_dir))

from config import settings
from models.platform_rules import PlatformType, get_platform_rules
from models.content import VideoTranscript, PlatformContent

logger = logging.getLogger(__name__)


class ContentOrchestrator:
    """Simplified orchestrator for generating platform-specific content from video transcripts."""
    
    def __init__(self, model_name: str = "gpt-4o"):
        self.model_name = model_name
        self.agent = self._create_agent()
    
    def _create_agent(self) -> Agent:
        """Create the AI agent for content generation."""
        model = OpenAIModel(self.model_name)
        
        system_prompt = """You are an expert social media content creator.
        
Your task is to generate platform-specific titles and tags from video transcripts.
You understand each platform's unique requirements and audience expectations.

Always respond with a title and appropriate tags for the requested platform."""
        
        return Agent(model=model, system_prompt=system_prompt)
    
    async def generate_content(self, platform: PlatformType, transcript: VideoTranscript) -> PlatformContent:
        """Generate content for a specific platform from a video transcript."""
        rules = get_platform_rules(platform)
        
        # Build the prompt with platform rules
        prompt = f"""
Generate a {platform.value} post from this video transcript.

Platform Rules:
- Title: Maximum {rules.title_max_length} characters
- Tags: {rules.tag_min_count} to {rules.tag_max_count} tags
- Style: {rules.content_style}

Video Transcript:
"{transcript.content}"

{f'Original Title: {transcript.title}' if transcript.title else ''}

Requirements:
1. Create an engaging title that fits the platform's style
2. Generate {rules.tag_min_count}-{rules.tag_max_count} relevant hashtags
3. Match the platform's content style

Respond in this exact format:
Title: [your title here]
Tags: #tag1, #tag2, #tag3, etc.
"""
        
        try:
            # Get AI response
            result = await self.agent.run(prompt)
            content_text = result.output
            
            # Parse the response
            lines = content_text.strip().split('\n')
            title = ""
            tags = []
            
            for line in lines:
                if line.startswith("Title:"):
                    title = line.replace("Title:", "").strip()
                elif line.startswith("Tags:"):
                    tags_text = line.replace("Tags:", "").strip()
                    # Extract hashtags
                    tags = [tag.strip() for tag in tags_text.split(',')]
                    # Ensure hashtags start with #
                    tags = [f"#{tag.lstrip('#')}" if tag and not tag.startswith('#') else tag for tag in tags]
            
            # Create platform content
            content = PlatformContent(
                platform=platform,
                title=title or "Generated Content",
                tags=tags or [f"#{platform.value}"],
                confidence_score=0.85 if title and tags else 0.5
            )
            
            logger.info(f"Generated content for {platform.value}: {len(content.title)} chars, {len(content.tags)} tags")
            return content
            
        except Exception as e:
            logger.error(f"Content generation failed for {platform.value}: {e}")
            # Return fallback content
            return PlatformContent(
                platform=platform,
                title=f"{platform.value.title()} Post",
                tags=[f"#{platform.value}", "#video", "#content"],
                confidence_score=0.3
            )


# Global orchestrator instance
_content_orchestrator = None


def get_content_orchestrator() -> ContentOrchestrator:
    """Get global content orchestrator instance."""
    global _content_orchestrator
    if _content_orchestrator is None:
        _content_orchestrator = ContentOrchestrator()
    return _content_orchestrator

================
File: app/services/platform_agents.py
================
"""
Platform-specific AI agents for generating tailored social media content.
Each agent is specialized for a specific platform's audience, style, and requirements.
"""
from typing import Dict, List, Optional
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
from pydantic_ai.providers.openai import OpenAIProvider
import logging

import sys
from pathlib import Path

# Add parent directory to path for imports
parent_dir = Path(__file__).parent.parent
sys.path.insert(0, str(parent_dir))

from config import settings
from models.platform_rules import PlatformType, get_platform_rules
from models.content import VideoTranscript, PlatformContent

logger = logging.getLogger(__name__)


class PlatformSpecificAgent:
    """Base class for platform-specific AI agents."""
    
    def __init__(self, platform: PlatformType, model_name: str = "gpt-4o"):
        self.platform = platform
        self.model_name = model_name
        self.rules = get_platform_rules(platform)
        self.agent = self._create_agent()
    
    def _create_agent(self) -> Agent:
        """Create platform-specific AI agent."""
        provider = OpenAIProvider(api_key=settings.openai_api_key)
        model = OpenAIModel(self.model_name, provider=provider)
        
        return Agent(
            model=model,
            system_prompt=self._get_system_prompt()
        )
    
    def _get_system_prompt(self) -> str:
        """Get platform-specific system prompt. Override in subclasses."""
        raise NotImplementedError("Subclasses must implement _get_system_prompt")
    
    def _build_prompt(self, transcript: VideoTranscript, tone: str = "neutral", 
                     include_emojis: bool = True) -> str:
        """Build platform-specific content generation prompt."""
        raise NotImplementedError("Subclasses must implement _build_prompt")


class YouTubeAgent(PlatformSpecificAgent):
    """Specialized AI agent for YouTube content generation."""
    
    def __init__(self, model_name: str = "gpt-4o"):
        super().__init__(PlatformType.YOUTUBE, model_name)
    
    def _get_system_prompt(self) -> str:
        return """You are a YouTube content optimization expert with deep knowledge of YouTube's algorithm and audience behavior.

Your expertise includes:
- SEO optimization for YouTube search and discovery
- Creating compelling, click-worthy titles that don't feel clickbait
- Understanding trending topics and keywords
- Balancing educational value with entertainment
- YouTube-specific engagement strategies

Focus on:
- Educational/entertainment balance
- SEO-friendly titles with trending keywords
- 10-15 relevant, searchable tags
- Content that encourages views, likes, and subscriptions
- Titles that work well with thumbnail optimization

Always create content that YouTube's algorithm will favor while maintaining authenticity."""
    
    def _build_prompt(self, transcript: VideoTranscript, tone: str = "neutral", 
                     include_emojis: bool = True) -> str:
        emoji_instruction = "Include 1-2 relevant emojis" if include_emojis else "No emojis"
        
        return f"""
Create a YouTube-optimized title and tags for this video transcript.

TRANSCRIPT: "{transcript.content}"
ORIGINAL TITLE: {transcript.title or 'Not provided'}
CATEGORY: {transcript.video_category or 'General'}
TONE: {tone}
EMOJIS: {emoji_instruction}

YouTube Optimization Requirements:
- Title: Maximum 100 characters, SEO-optimized, engaging but not clickbait
- Tags: Exactly 10-15 hashtags focused on searchability and trending keywords
- Consider: What would make someone click while accurately representing the content?
- Include trending keywords relevant to the topic
- Think about what the target audience searches for

Respond with JSON:
{{
    "title": "your SEO-optimized YouTube title",
    "tags": ["#keyword1", "#keyword2", "#keyword3", "#keyword4", "#keyword5", "#keyword6", "#keyword7", "#keyword8", "#keyword9", "#keyword10"],
    "confidence": 0.9
}}
"""


class InstagramAgent(PlatformSpecificAgent):
    """Specialized AI agent for Instagram content generation."""
    
    def __init__(self, model_name: str = "gpt-4o"):
        super().__init__(PlatformType.INSTAGRAM, model_name)
    
    def _get_system_prompt(self) -> str:
        return """You are an Instagram content creator expert who understands visual storytelling and Instagram culture.

Your expertise includes:
- Visual-first content strategy
- Instagram's aesthetic and lifestyle focus
- Hashtag strategy for maximum reach
- Community engagement tactics
- Instagram Reels and Stories optimization

Focus on:
- Visual appeal and lifestyle branding
- 20-30 strategic hashtags (mix of popular and niche)
- Content that encourages saves, shares, and comments
- Authentic, relatable captions
- Trend awareness and aesthetic consistency

Create content that fits Instagram's visual-first, lifestyle-focused environment."""
    
    def _build_prompt(self, transcript: VideoTranscript, tone: str = "neutral", 
                     include_emojis: bool = True) -> str:
        emoji_instruction = "Include 3-5 relevant emojis for visual appeal" if include_emojis else "No emojis"
        
        return f"""
Create Instagram-optimized caption and hashtags for this video content.

TRANSCRIPT: "{transcript.content}"
ORIGINAL TITLE: {transcript.title or 'Not provided'}
CATEGORY: {transcript.video_category or 'General'}
TONE: {tone}
EMOJIS: {emoji_instruction}

Instagram Optimization Requirements:
- Caption: Maximum 150 characters, visually appealing, lifestyle-focused
- Hashtags: Exactly 20-30 hashtags (mix trending + niche + community hashtags)
- Consider: Visual storytelling, community engagement, shareability
- Think lifestyle and aesthetic appeal
- Include call-to-action for engagement

Mix hashtag types:
- Trending hashtags (high volume)
- Niche hashtags (targeted audience)
- Community hashtags (specific interests)
- Branded/content hashtags

Respond with JSON:
{{
    "title": "your Instagram caption",
    "tags": ["#hashtag1", "#hashtag2", ... "hashtag20-30"],
    "confidence": 0.9
}}
"""


class FacebookAgent(PlatformSpecificAgent):
    """Specialized AI agent for Facebook content generation."""
    
    def __init__(self, model_name: str = "gpt-4o"):
        super().__init__(PlatformType.FACEBOOK, model_name)
    
    def _get_system_prompt(self) -> str:
        return """You are a Facebook community engagement specialist who understands how to create shareable, discussion-worthy content.

Your expertise includes:
- Community building and engagement
- Content that encourages meaningful discussions
- Facebook's algorithm preferences for social interaction
- Cross-generational appeal
- Share-worthy content creation

Focus on:
- Community building and conversation starters
- Shareable, relatable content
- Minimal hashtag usage (3-5 only)
- Content that generates comments and shares
- Family-friendly, inclusive messaging

Create content that brings people together and encourages community interaction."""
    
    def _build_prompt(self, transcript: VideoTranscript, tone: str = "neutral", 
                     include_emojis: bool = True) -> str:
        emoji_instruction = "Include 1-2 emojis for warmth" if include_emojis else "No emojis"
        
        return f"""
Create Facebook-optimized post for this video content.

TRANSCRIPT: "{transcript.content}"
ORIGINAL TITLE: {transcript.title or 'Not provided'}
CATEGORY: {transcript.video_category or 'General'}
TONE: {tone}
EMOJIS: {emoji_instruction}

Facebook Optimization Requirements:
- Post: Maximum 255 characters, community-focused, conversation-starting
- Hashtags: Only 3-5 hashtags (Facebook users prefer minimal hashtag usage)
- Consider: What would make people share this with friends/family?
- Include question or call-to-action to encourage comments
- Focus on building community and sparking discussion

Create content that people want to share and discuss with their network.

Respond with JSON:
{{
    "title": "your Facebook post",
    "tags": ["#hashtag1", "#hashtag2", "#hashtag3"],
    "confidence": 0.9
}}
"""


class TikTokAgent(PlatformSpecificAgent):
    """Specialized AI agent for TikTok content generation."""
    
    def __init__(self, model_name: str = "gpt-4o"):
        super().__init__(PlatformType.TIKTOK, model_name)
    
    def _get_system_prompt(self) -> str:
        return """You are a TikTok content creator who understands viral trends, Gen-Z culture, and the TikTok algorithm.

Your expertise includes:
- Viral content creation and trend awareness
- Gen-Z language and cultural references
- TikTok's fast-paced, entertainment-first environment
- Trend participation and hashtag challenges
- Short-form video optimization

Focus on:
- Trendy, catchy, viral potential content
- Gen-Z friendly language and references
- 3-5 trending hashtags
- Content that hooks viewers immediately
- Trend awareness and cultural relevance

Create content that has the potential to go viral while staying authentic to current TikTok culture."""
    
    def _build_prompt(self, transcript: VideoTranscript, tone: str = "neutral", 
                     include_emojis: bool = True) -> str:
        emoji_instruction = "Include trending emojis (2-4)" if include_emojis else "No emojis"
        
        return f"""
Create TikTok-optimized caption and hashtags for this video content.

TRANSCRIPT: "{transcript.content}"
ORIGINAL TITLE: {transcript.title or 'Not provided'}
CATEGORY: {transcript.video_category or 'General'}
TONE: {tone} (but make it TikTok-trendy)
EMOJIS: {emoji_instruction}

TikTok Optimization Requirements:
- Caption: Maximum 150 characters, catchy, trend-aware, Gen-Z friendly
- Hashtags: Exactly 3-5 hashtags focusing on trending topics
- Consider: What would make someone stop scrolling and watch?
- Use current TikTok language and trends
- Create immediate hook and viral potential

Think viral, trendy, and authentic to TikTok culture.

Respond with JSON:
{{
    "title": "your TikTok caption",
    "tags": ["#trending1", "#viral2", "#fyp", "#hashtag4", "#hashtag5"],
    "confidence": 0.9
}}
"""


class XTwitterAgent(PlatformSpecificAgent):
    """Specialized AI agent for X (Twitter) content generation."""
    
    def __init__(self, model_name: str = "gpt-4o"):
        super().__init__(PlatformType.X_TWITTER, model_name)
    
    def _get_system_prompt(self) -> str:
        return """You are an X (Twitter) content strategist who understands real-time conversations, trending topics, and Twitter culture.

Your expertise includes:
- Real-time engagement and trending topics
- Concise, impactful messaging
- Twitter's conversation-driven environment
- Hashtag integration within natural text
- Current events and cultural moment awareness

Focus on:
- Concise, conversation-starting content
- Hashtags integrated naturally into the text
- 2-3 hashtags maximum within 280 character total limit
- Content that sparks replies and retweets
- Timely, relevant messaging

Create content that starts conversations and engages with the current Twitter discourse."""
    
    def _build_prompt(self, transcript: VideoTranscript, tone: str = "neutral", 
                     include_emojis: bool = True) -> str:
        emoji_instruction = "Include 1-2 relevant emojis" if include_emojis else "No emojis"
        
        return f"""
Create X (Twitter) optimized post for this video content.

TRANSCRIPT: "{transcript.content}"
ORIGINAL TITLE: {transcript.title or 'Not provided'}
CATEGORY: {transcript.video_category or 'General'}
TONE: {tone}
EMOJIS: {emoji_instruction}

Twitter/X Optimization Requirements:
- Total: Maximum 280 characters INCLUDING hashtags and spaces
- Hashtags: 2-3 hashtags integrated naturally into the text
- Consider: What would make people want to reply, retweet, or quote tweet?
- Make it conversation-worthy and timely
- Integrate hashtags naturally (not just at the end)

CRITICAL: Ensure total character count (text + hashtags + spaces) ≤ 280 characters.

Respond with JSON:
{{
    "title": "your complete Twitter/X post with hashtags integrated",
    "tags": ["#hashtag1", "#hashtag2"],
    "confidence": 0.9
}}
"""


class LinkedInAgent(PlatformSpecificAgent):
    """Specialized AI agent for LinkedIn content generation."""
    
    def __init__(self, model_name: str = "gpt-4o"):
        super().__init__(PlatformType.LINKEDIN, model_name)
    
    def _get_system_prompt(self) -> str:
        return """You are a LinkedIn thought leadership expert who understands professional networking and industry discourse.

Your expertise includes:
- Professional content strategy and thought leadership
- Industry insights and professional development
- LinkedIn's business-focused environment
- Professional networking and career growth
- B2B content and industry trends

Focus on:
- Professional, authoritative tone
- Industry-relevant insights and value
- 3-5 professional/industry hashtags
- Content that positions the creator as a thought leader
- Professional networking and career development angle

Create content that enhances professional reputation and provides industry value."""
    
    def _build_prompt(self, transcript: VideoTranscript, tone: str = "professional", 
                     include_emojis: bool = False) -> str:
        # LinkedIn typically uses fewer emojis
        emoji_instruction = "Include 1 professional emoji if relevant" if include_emojis else "No emojis"
        
        return f"""
Create LinkedIn-optimized post for this video content.

TRANSCRIPT: "{transcript.content}"
ORIGINAL TITLE: {transcript.title or 'Not provided'}
CATEGORY: {transcript.video_category or 'General'}
TONE: Professional and thought-leadership focused
EMOJIS: {emoji_instruction}

LinkedIn Optimization Requirements:
- Post: Maximum 210 characters, professional tone, industry-focused
- Hashtags: Exactly 3-5 professional/industry hashtags
- Consider: How does this provide professional value to my network?
- Position as thought leadership or industry insight
- Focus on professional development, industry trends, or business value

Create content that enhances professional credibility and provides value to professional networks.

Respond with JSON:
{{
    "title": "your LinkedIn post",
    "tags": ["#industry1", "#professional2", "#thoughtleadership", "#hashtag4", "#hashtag5"],
    "confidence": 0.9
}}
"""


class TwitchAgent(PlatformSpecificAgent):
    """Specialized AI agent for Twitch content generation."""
    
    def __init__(self, model_name: str = "gpt-4o"):
        super().__init__(PlatformType.TWITCH, model_name)
    
    def _get_system_prompt(self) -> str:
        return """You are a Twitch streaming expert who understands gaming culture, streaming community, and interactive content.

Your expertise includes:
- Gaming community culture and terminology
- Interactive streaming content
- Twitch-specific engagement tactics
- Gaming trends and community building
- Live streaming and audience interaction

Focus on:
- Gaming and streaming community focus
- Interactive, community-oriented content
- 3-8 gaming/streaming hashtags
- Content that encourages live interaction
- Gaming terminology and community references

Create content that resonates with the gaming and streaming community."""
    
    def _build_prompt(self, transcript: VideoTranscript, tone: str = "energetic", 
                     include_emojis: bool = True) -> str:
        emoji_instruction = "Include gaming-related emojis (2-3)" if include_emojis else "No emojis"
        
        return f"""
Create Twitch-optimized title and tags for this video content.

TRANSCRIPT: "{transcript.content}"
ORIGINAL TITLE: {transcript.title or 'Not provided'}
CATEGORY: {transcript.video_category or 'Gaming'}
TONE: Energetic and community-focused
EMOJIS: {emoji_instruction}

Twitch Optimization Requirements:
- Title: Maximum 140 characters, gaming/streaming focused, energetic
- Hashtags: 3-8 hashtags focusing on gaming categories and community
- Consider: What would make gamers want to join the stream?
- Use gaming terminology and community language
- Focus on interactive and community aspects

Create content that appeals to the gaming and streaming community.

Respond with JSON:
{{
    "title": "your Twitch stream title",
    "tags": ["#gaming", "#live", "#twitch", "#community", "#hashtag5"],
    "confidence": 0.9
}}
"""


class PlatformAgentManager:
    """Manager for all platform-specific AI agents."""
    
    def __init__(self):
        self.agents: Dict[PlatformType, PlatformSpecificAgent] = {
            PlatformType.YOUTUBE: YouTubeAgent(),
            PlatformType.INSTAGRAM: InstagramAgent(),
            PlatformType.FACEBOOK: FacebookAgent(),
            PlatformType.TIKTOK: TikTokAgent(),
            PlatformType.X_TWITTER: XTwitterAgent(),
            PlatformType.LINKEDIN: LinkedInAgent(),
            PlatformType.TWITCH: TwitchAgent()
        }
    
    def get_agent(self, platform: PlatformType) -> PlatformSpecificAgent:
        """Get specialized agent for a specific platform."""
        return self.agents[platform]
    
    async def generate_content(self, platform: PlatformType, transcript: VideoTranscript,
                        tone: str = "neutral", include_emojis: bool = True) -> PlatformContent:
        """Generate content using platform-specific agent."""
        agent = self.get_agent(platform)
        prompt = agent._build_prompt(transcript, tone, include_emojis)
        
        try:
            # Generate content using the specialized agent (async)
            result = await agent.agent.run(prompt)
            ai_response = result.output
            
            # Parse response
            if isinstance(ai_response, str):
                import json
                try:
                    ai_response = json.loads(ai_response)
                except json.JSONDecodeError:
                    # Simple fallback parsing
                    ai_response = {"title": "Generated Content", "tags": ["#content"], "confidence": 0.7}
            
            # Create platform content
            content = PlatformContent(
                platform=platform,
                title=ai_response.get("title", "Generated Title"),
                tags=ai_response.get("tags", ["#content"]),
                confidence_score=float(ai_response.get("confidence", 0.7))
            )
            
            # Validate against platform rules
            rules = get_platform_rules(platform)
            content.validate_against_platform_rules(rules)
            
            return content
            
        except Exception as e:
            logger.error(f"Platform-specific content generation failed for {platform.value}: {e}")
            raise


# Global agent manager instance
_platform_agent_manager = None


def get_platform_agent_manager() -> PlatformAgentManager:
    """Get global platform agent manager instance."""
    global _platform_agent_manager
    if _platform_agent_manager is None:
        _platform_agent_manager = PlatformAgentManager()
    return _platform_agent_manager

================
File: app/services/speech_to_text.py
================
import os
from dotenv import load_dotenv
from io import BytesIO
import requests
from elevenlabs.client import ElevenLabs

load_dotenv()

def get_transcription(audio_url: str, model_id: str = "scribe_v1", language_code: str = "eng", diarize: bool = True, tag_audio_events: bool = True) -> str:
    elevenlabs = ElevenLabs(
        api_key=os.getenv("ELEVEN_LABS_API_KEY"),
    )

    response = requests.get(audio_url)
    audio_data = BytesIO(response.content)

    transcription = elevenlabs.speech_to_text.convert(
        file=audio_data,
        model_id=model_id, # Model to use, for now only "scribe_v1" is supported
        tag_audio_events=tag_audio_events, # Tag audio events like laughter, applause, etc.
        language_code=language_code, # Language of the audio file. If set to None, the model will detect the language automatically.
        diarize=diarize, # Whether to annotate who is speaking
    )

    return transcription

================
File: app/services/transcript_processor.py
================
"""
Transcript processing service for cleaning, summarizing, and extracting key themes
from video transcripts before content generation.
"""
import re
import logging
from typing import List, Dict, Optional, Tuple
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
from pydantic_ai.providers.openai import OpenAIProvider
from pydantic import BaseModel

import sys
from pathlib import Path

# Add parent directory to path for imports
parent_dir = Path(__file__).parent.parent
sys.path.insert(0, str(parent_dir))

from config import settings
from models.content import VideoTranscript

logger = logging.getLogger(__name__)


class TranscriptAnalysis(BaseModel):
    """Analysis results for a processed transcript."""
    
    cleaned_content: str
    key_themes: List[str]
    summary: str
    tone: str
    category: Optional[str] = None
    keywords: List[str]
    sentiment: str
    word_count: int
    estimated_reading_time: int  # in seconds


class TranscriptProcessor:
    """Service for processing and analyzing video transcripts."""
    
    def __init__(self, model_name: str = "gpt-4o"):
        self.model_name = model_name
        self.agent = self._create_analysis_agent()
        
        # Common words to filter out from keywords
        self.stop_words = {
            'the', 'be', 'to', 'of', 'and', 'a', 'in', 'that', 'have',
            'i', 'it', 'for', 'not', 'on', 'with', 'he', 'as', 'you',
            'do', 'at', 'this', 'but', 'his', 'by', 'from', 'they',
            'we', 'say', 'her', 'she', 'or', 'an', 'will', 'my',
            'one', 'all', 'would', 'there', 'their', 'what', 'so',
            'up', 'out', 'if', 'about', 'who', 'get', 'which', 'go',
            'me', 'when', 'make', 'can', 'like', 'time', 'no', 'just',
            'him', 'know', 'take', 'people', 'into', 'year', 'your',
            'good', 'some', 'could', 'them', 'see', 'other', 'than',
            'then', 'now', 'look', 'only', 'come', 'its', 'over',
            'think', 'also', 'back', 'after', 'use', 'two', 'how',
            'our', 'work', 'first', 'well', 'way', 'even', 'new',
            'want', 'because', 'any', 'these', 'give', 'day', 'most', 'us'
        }
    
    def _create_analysis_agent(self) -> Agent:
        """Create AI agent for transcript analysis."""
        provider = OpenAIProvider(api_key=settings.openai_api_key)
        model = OpenAIModel(self.model_name, provider=provider)
        
        system_prompt = """You are an expert content analyst specializing in video transcript analysis.

Your expertise includes:
- Identifying key themes and topics in video content
- Extracting relevant keywords for social media optimization
- Determining content tone and sentiment
- Categorizing content types
- Creating concise, accurate summaries
- Understanding context and meaning

Focus on:
- Accuracy in theme identification
- Relevant keyword extraction for social media
- Appropriate tone and sentiment analysis
- Clear, concise summaries
- Content categorization for better targeting

Always provide structured, actionable insights for social media content creation."""
        
        return Agent(model=model, system_prompt=system_prompt)
    
    def clean_transcript(self, raw_content: str) -> str:
        """Clean and normalize transcript content."""
        if not raw_content:
            return ""
        
        # Remove excessive whitespace
        content = re.sub(r'\s+', ' ', raw_content.strip())
        
        # Remove common transcript artifacts
        content = re.sub(r'\[.*?\]', '', content)  # Remove [music], [applause] etc.
        content = re.sub(r'\(.*?\)', '', content)  # Remove (inaudible), (laughter) etc.
        
        # Remove speaker indicators like "Speaker 1:", "Host:", etc.
        content = re.sub(r'^[A-Za-z0-9\s]+:\s*', '', content, flags=re.MULTILINE)
        content = re.sub(r'\s+[A-Za-z0-9\s]+:\s*', ' ', content)  # Remove mid-line speaker indicators
        
        # Remove timestamps like "00:12" or "1:23:45"
        content = re.sub(r'\b\d{1,2}:\d{2}(?::\d{2})?\b', '', content)
        
        # Remove filler words and hesitations
        filler_words = ['um', 'uh', 'hmm', 'er', 'ah', 'like', 'you know', 'so']
        for filler in filler_words:
            content = re.sub(rf'\b{filler}\b', '', content, flags=re.IGNORECASE)
        
        # Clean up multiple spaces and punctuation
        content = re.sub(r'\s+', ' ', content)
        content = re.sub(r'[,;]\s*[,;]+', ',', content)  # Multiple commas/semicolons
        content = re.sub(r'\.\s*\.+', '.', content)  # Multiple periods
        
        # Ensure proper sentence structure
        content = re.sub(r'(?<=[a-z])\s+(?=[A-Z])', '. ', content)
        
        return content.strip()
    
    def extract_keywords(self, content: str, max_keywords: int = 15) -> List[str]:
        """Extract relevant keywords from content."""
        # Convert to lowercase and split into words
        words = re.findall(r'\b[a-zA-Z]{3,}\b', content.lower())
        
        # Filter out stop words
        keywords = [word for word in words if word not in self.stop_words]
        
        # Count frequency
        word_freq = {}
        for word in keywords:
            word_freq[word] = word_freq.get(word, 0) + 1
        
        # Sort by frequency and return top keywords
        sorted_keywords = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        
        # For shorter content, include single-occurrence words; for longer content, require freq > 1
        min_freq = 1 if len(keywords) < 50 else 2
        return [word for word, freq in sorted_keywords[:max_keywords] if freq >= min_freq]
    
    def estimate_reading_time(self, content: str) -> int:
        """Estimate reading time in seconds (average 200 WPM)."""
        word_count = len(content.split())
        # Average reading speed: 200 words per minute
        return int((word_count / 200) * 60)
    
    def determine_basic_tone(self, content: str) -> str:
        """Determine basic tone from content using simple heuristics."""
        content_lower = content.lower()
        
        # Positive indicators
        positive_words = ['great', 'amazing', 'excellent', 'fantastic', 'wonderful', 
                         'awesome', 'brilliant', 'perfect', 'love', 'best']
        
        # Negative indicators
        negative_words = ['terrible', 'awful', 'horrible', 'worst', 'hate', 
                         'bad', 'problem', 'issue', 'difficult', 'challenging']
        
        # Professional indicators
        professional_words = ['research', 'analysis', 'strategy', 'methodology',
                             'framework', 'implementation', 'optimization']
        
        # Casual indicators
        casual_words = ['hey', 'guys', 'folks', 'cool', 'fun', 'awesome', 'epic']
        
        positive_count = sum(1 for word in positive_words if word in content_lower)
        negative_count = sum(1 for word in negative_words if word in content_lower)
        professional_count = sum(1 for word in professional_words if word in content_lower)
        casual_count = sum(1 for word in casual_words if word in content_lower)
        
        if professional_count > casual_count:
            return "professional"
        elif casual_count > professional_count:
            return "casual"
        elif positive_count > negative_count:
            return "positive"
        elif negative_count > positive_count:
            return "serious"
        else:
            return "neutral"
    
    async def analyze_transcript_with_ai(self, transcript: VideoTranscript) -> TranscriptAnalysis:
        """Analyze transcript using AI for detailed insights."""
        cleaned_content = self.clean_transcript(transcript.content)
        
        # Check if content needs summarization (>1000 words)
        word_count = len(cleaned_content.split())
        needs_summary = word_count > 1000
        
        analysis_prompt = f"""
Analyze this video transcript and provide structured insights for social media content creation.

TRANSCRIPT: "{cleaned_content}"
ORIGINAL TITLE: {transcript.title or 'Not provided'}
CATEGORY: {transcript.video_category or 'Not specified'}

Please analyze and provide:

1. KEY THEMES: Identify 3-5 main themes or topics discussed
2. SUMMARY: Create a concise summary (2-3 sentences) capturing the essence
3. TONE: Determine the overall tone (professional, casual, energetic, educational, entertaining, etc.)
4. CONTENT CATEGORY: Categorize the content (tech, lifestyle, education, gaming, business, etc.)
5. KEYWORDS: Extract 8-12 important keywords relevant for social media hashtags
6. SENTIMENT: Overall sentiment (positive, neutral, negative, mixed)

{"If the content is very long, focus on the most important themes and create a condensed summary." if needs_summary else ""}

Respond with JSON in this exact format:
{{
    "key_themes": ["theme1", "theme2", "theme3"],
    "summary": "2-3 sentence summary of the main content",
    "tone": "content tone",
    "category": "content category",
    "keywords": ["keyword1", "keyword2", "keyword3", "keyword4", "keyword5", "keyword6", "keyword7", "keyword8"],
    "sentiment": "overall sentiment"
}}
"""
        
        try:
            # Get AI analysis (async)
            result = await self.agent.run(analysis_prompt)
            ai_response = result.output
            
            # Parse AI response
            if isinstance(ai_response, str):
                import json
                try:
                    analysis_data = json.loads(ai_response)
                except json.JSONDecodeError:
                    # Fallback to basic analysis
                    return self._create_basic_analysis(cleaned_content, transcript)
            else:
                analysis_data = ai_response
            
            # Create analysis object
            analysis = TranscriptAnalysis(
                cleaned_content=cleaned_content,
                key_themes=analysis_data.get("key_themes", ["general"]),
                summary=analysis_data.get("summary", "Content summary not available"),
                tone=analysis_data.get("tone", self.determine_basic_tone(cleaned_content)),
                category=analysis_data.get("category", transcript.video_category),
                keywords=analysis_data.get("keywords", self.extract_keywords(cleaned_content, 10)),
                sentiment=analysis_data.get("sentiment", "neutral"),
                word_count=word_count,
                estimated_reading_time=self.estimate_reading_time(cleaned_content)
            )
            
            logger.info(f"Transcript analyzed successfully: {word_count} words, {len(analysis.key_themes)} themes")
            return analysis
            
        except Exception as e:
            logger.error(f"AI analysis failed, falling back to basic analysis: {e}")
            return self._create_basic_analysis(cleaned_content, transcript)
    
    def _create_basic_analysis(self, cleaned_content: str, transcript: VideoTranscript) -> TranscriptAnalysis:
        """Create basic analysis when AI analysis fails."""
        word_count = len(cleaned_content.split())
        keywords = self.extract_keywords(cleaned_content, 10)
        
        # Simple summary (first 2 sentences)
        sentences = re.split(r'[.!?]+', cleaned_content)
        summary = '. '.join(sentences[:2]).strip()
        if summary and not summary.endswith('.'):
            summary += '.'
        
        return TranscriptAnalysis(
            cleaned_content=cleaned_content,
            key_themes=keywords[:3] if keywords else ["content"],
            summary=summary or "Content summary not available",
            tone=self.determine_basic_tone(cleaned_content),
            category=transcript.video_category or "general",
            keywords=keywords,
            sentiment="neutral",
            word_count=word_count,
            estimated_reading_time=self.estimate_reading_time(cleaned_content)
        )
    
    async def process_transcript(self, transcript: VideoTranscript) -> Tuple[VideoTranscript, TranscriptAnalysis]:
        """Process transcript and return cleaned version with analysis."""
        try:
            # Analyze transcript
            analysis = await self.analyze_transcript_with_ai(transcript)
            
            # Create enhanced transcript
            enhanced_transcript = VideoTranscript(
                content=analysis.cleaned_content,
                title=transcript.title,
                duration_seconds=transcript.duration_seconds,
                language=transcript.language,
                video_category=analysis.category or transcript.video_category,
                metadata={
                    **transcript.metadata,
                    "word_count": analysis.word_count,
                    "estimated_reading_time": analysis.estimated_reading_time,
                    "key_themes": analysis.key_themes,
                    "tone": analysis.tone,
                    "sentiment": analysis.sentiment
                }
            )
            
            logger.info("Transcript processing completed successfully")
            return enhanced_transcript, analysis
            
        except Exception as e:
            logger.error(f"Transcript processing failed: {e}")
            # Return original transcript with basic cleaning
            cleaned_content = self.clean_transcript(transcript.content)
            basic_analysis = self._create_basic_analysis(cleaned_content, transcript)
            
            enhanced_transcript = VideoTranscript(
                content=cleaned_content,
                title=transcript.title,
                duration_seconds=transcript.duration_seconds,
                language=transcript.language,
                video_category=transcript.video_category,
                metadata=transcript.metadata
            )
            
            return enhanced_transcript, basic_analysis
    
    def get_content_suggestions(self, analysis: TranscriptAnalysis) -> Dict[str, List[str]]:
        """Get content suggestions based on transcript analysis."""
        suggestions = {
            "title_keywords": analysis.keywords[:5],
            "hashtag_suggestions": [f"#{keyword}" for keyword in analysis.keywords[:8]],
            "tone_recommendations": [],
            "platform_suggestions": []
        }
        
        # Tone recommendations based on analysis
        if analysis.tone == "professional":
            suggestions["tone_recommendations"] = ["LinkedIn", "formal", "business-focused"]
            suggestions["platform_suggestions"] = ["LinkedIn", "Facebook"]
        elif analysis.tone == "casual":
            suggestions["tone_recommendations"] = ["Instagram", "TikTok", "friendly"]
            suggestions["platform_suggestions"] = ["Instagram", "TikTok", "X/Twitter"]
        elif analysis.tone == "educational":
            suggestions["tone_recommendations"] = ["YouTube", "informative", "tutorial"]
            suggestions["platform_suggestions"] = ["YouTube", "LinkedIn"]
        else:
            suggestions["tone_recommendations"] = ["adaptable", "versatile"]
            suggestions["platform_suggestions"] = ["YouTube", "Instagram", "Facebook"]
        
        # Category-based suggestions
        if analysis.category:
            category_lower = analysis.category.lower()
            if "tech" in category_lower or "ai" in category_lower:
                suggestions["platform_suggestions"].extend(["LinkedIn", "X/Twitter"])
            elif "gaming" in category_lower:
                suggestions["platform_suggestions"].extend(["Twitch", "TikTok"])
            elif "lifestyle" in category_lower:
                suggestions["platform_suggestions"].extend(["Instagram", "Facebook"])
        
        # Remove duplicates
        suggestions["platform_suggestions"] = list(set(suggestions["platform_suggestions"]))
        
        return suggestions


# Global transcript processor instance
_transcript_processor = None


def get_transcript_processor() -> TranscriptProcessor:
    """Get global transcript processor instance."""
    global _transcript_processor
    if _transcript_processor is None:
        _transcript_processor = TranscriptProcessor()
    return _transcript_processor

================
File: app/tests/__init__.py
================
"""
Test suite for the Video Transcript to Social Media Content Generator.
Contains unit tests, integration tests, and performance tests.
"""

================
File: app/tests/test_ai_services.py
================
"""
Tests for AI content generation services.
Tests base AI service, platform-specific agents, and transcript processing.
"""
import sys
from pathlib import Path

# Add the parent directory to Python path
parent_dir = Path(__file__).parent.parent
sys.path.insert(0, str(parent_dir))

import pytest
from unittest.mock import Mock, patch
from models.platform_rules import PlatformType
from models.content import VideoTranscript, PlatformContent
from services.content_generator import ContentGeneratorService, ContentGenerationRequest
from services.platform_agents import PlatformAgentManager, get_platform_agent_manager
from services.transcript_processor import TranscriptProcessor, TranscriptAnalysis


class TestContentGeneratorService:
    """Test base AI content generation service."""
    
    def test_service_initialization(self):
        """Test that the service initializes correctly."""
        # Mock to avoid actual API calls
        with patch('services.content_generator.settings') as mock_settings:
            mock_settings.openai_api_key = "test_key"
            
            with patch('services.content_generator.OpenAIProvider') as mock_provider:
                with patch('services.content_generator.OpenAIModel') as mock_model:
                    with patch('services.content_generator.Agent') as mock_agent:
                        service = ContentGeneratorService()
                        
                        assert service.model_name == "gpt-4o"
                        assert service.model is not None
                        assert service.agent is not None
    
    def test_base_system_prompt(self):
        """Test base system prompt contains key elements."""
        with patch('services.content_generator.settings') as mock_settings:
            mock_settings.openai_api_key = "test_key"
            
            with patch('services.content_generator.OpenAIProvider'):
                with patch('services.content_generator.OpenAIModel'):
                    with patch('services.content_generator.Agent'):
                        service = ContentGeneratorService()
                        prompt = service._get_base_system_prompt()
                        
                        # Check key elements are present
                        assert "social media" in prompt.lower()
                        assert "platform" in prompt.lower()
                        assert "engagement" in prompt.lower()
                        assert "json" in prompt.lower()
    
    def test_platform_prompt_building(self):
        """Test platform-specific prompt building."""
        transcript = VideoTranscript(
            content="This is a test video about artificial intelligence and machine learning.",
            title="AI Tutorial",
            video_category="technology"
        )
        
        with patch('services.content_generator.settings') as mock_settings:
            mock_settings.openai_api_key = "test_key"
            
            with patch('services.content_generator.OpenAIProvider'):
                with patch('services.content_generator.OpenAIModel'):
                    with patch('services.content_generator.Agent'):
                        service = ContentGeneratorService()
                        
                        prompt = service._build_platform_prompt(
                            PlatformType.YOUTUBE, transcript, "energetic", True
                        )
                        
                        # Check platform-specific elements
                        assert "YOUTUBE" in prompt
                        assert "100 characters" in prompt  # YouTube title limit
                        assert "10-15" in prompt  # YouTube tag range
                        assert "energetic" in prompt
                        assert transcript.content in prompt
    
    def test_fallback_response_parsing(self):
        """Test fallback response parsing when JSON is malformed."""
        with patch('services.content_generator.settings') as mock_settings:
            mock_settings.openai_api_key = "test_key"
            
            with patch('services.content_generator.OpenAIProvider'):
                with patch('services.content_generator.OpenAIModel'):
                    with patch('services.content_generator.Agent'):
                        service = ContentGeneratorService()
                        
                        # Test malformed JSON response
                        malformed_response = '''
                        "title": "Great AI Tutorial",
                        "tags": ["#AI", "#tutorial", "#tech"],
                        "confidence": 0.9
                        '''
                        
                        parsed = service._parse_fallback_response(malformed_response)
                        
                        assert "title" in parsed
                        assert "tags" in parsed
                        assert "confidence" in parsed
                        assert isinstance(parsed["tags"], list)


class TestPlatformAgentManager:
    """Test platform-specific AI agents."""
    
    def test_agent_manager_initialization(self):
        """Test that agent manager initializes all platform agents."""
        with patch('services.platform_agents.settings') as mock_settings:
            mock_settings.openai_api_key = "test_key"
            
            with patch('services.platform_agents.OpenAIProvider'):
                with patch('services.platform_agents.OpenAIModel'):
                    with patch('services.platform_agents.Agent'):
                        manager = PlatformAgentManager()
                        
                        # Check all platforms have agents
                        assert len(manager.agents) == 7
                        
                        for platform in PlatformType:
                            assert platform in manager.agents
                            agent = manager.get_agent(platform)
                            assert agent is not None
                            assert agent.platform == platform
    
    def test_youtube_agent_prompts(self):
        """Test YouTube agent creates appropriate prompts."""
        transcript = VideoTranscript(
            content="Learn how to build AI applications from scratch in this comprehensive tutorial."
        )
        
        with patch('services.platform_agents.settings') as mock_settings:
            mock_settings.openai_api_key = "test_key"
            
            with patch('services.platform_agents.OpenAIProvider'):
                with patch('services.platform_agents.OpenAIModel'):
                    with patch('services.platform_agents.Agent'):
                        manager = PlatformAgentManager()
                        youtube_agent = manager.get_agent(PlatformType.YOUTUBE)
                        
                        prompt = youtube_agent._build_prompt(transcript)
                        
                        # Check YouTube-specific elements
                        assert "YouTube" in prompt
                        assert "SEO" in prompt
                        assert "100 characters" in prompt
                        assert "10-15" in prompt
    
    def test_instagram_agent_prompts(self):
        """Test Instagram agent creates appropriate prompts."""
        transcript = VideoTranscript(
            content="Check out this amazing sunset view from my latest travel adventure!"
        )
        
        with patch('services.platform_agents.settings') as mock_settings:
            mock_settings.openai_api_key = "test_key"
            
            with patch('services.platform_agents.OpenAIProvider'):
                with patch('services.platform_agents.OpenAIModel'):
                    with patch('services.platform_agents.Agent'):
                        manager = PlatformAgentManager()
                        instagram_agent = manager.get_agent(PlatformType.INSTAGRAM)
                        
                        prompt = instagram_agent._build_prompt(transcript)
                        
                        # Check Instagram-specific elements
                        assert "Instagram" in prompt
                        assert "150 characters" in prompt
                        assert "20-30" in prompt
                        assert "visual" in prompt.lower()
    
    def test_twitter_agent_character_limit(self):
        """Test X/Twitter agent emphasizes character limit."""
        transcript = VideoTranscript(
            content="Breaking news in the AI world: new developments that will change everything!"
        )
        
        with patch('services.platform_agents.settings') as mock_settings:
            mock_settings.openai_api_key = "test_key"
            
            with patch('services.platform_agents.OpenAIProvider'):
                with patch('services.platform_agents.OpenAIModel'):
                    with patch('services.platform_agents.Agent'):
                        manager = PlatformAgentManager()
                        twitter_agent = manager.get_agent(PlatformType.X_TWITTER)
                        
                        prompt = twitter_agent._build_prompt(transcript)
                        
                        # Check Twitter-specific elements
                        assert "280 characters" in prompt
                        assert "total character count" in prompt.lower()
                        assert "hashtags integrated" in prompt.lower()


class TestTranscriptProcessor:
    """Test transcript processing service."""
    
    def test_transcript_cleaning(self):
        """Test transcript cleaning functionality."""
        with patch('services.transcript_processor.settings') as mock_settings:
            mock_settings.openai_api_key = "test_key"
            
            with patch('services.transcript_processor.OpenAIProvider'):
                with patch('services.transcript_processor.OpenAIModel'):
                    with patch('services.transcript_processor.Agent'):
                        processor = TranscriptProcessor()
                        
                        raw_transcript = """
                        [music] Host: Welcome everyone um to this uh amazing tutorial.
                        Speaker 1: Yes, like, you know, this is going to be great!
                        00:12 [applause] (inaudible) Let's get started with AI.
                        """
                        
                        cleaned = processor.clean_transcript(raw_transcript)
                        
                        # Check cleaning worked
                        assert "[music]" not in cleaned
                        assert "[applause]" not in cleaned
                        assert "(inaudible)" not in cleaned
                        assert "Host:" not in cleaned
                        assert "Speaker 1:" not in cleaned
                        assert "00:12" not in cleaned
                        assert "um" not in cleaned
                        assert "uh" not in cleaned
                        assert "like" not in cleaned
                        assert len(cleaned) > 0
    
    def test_keyword_extraction(self):
        """Test keyword extraction from content."""
        with patch('services.transcript_processor.settings') as mock_settings:
            mock_settings.openai_api_key = "test_key"
            
            with patch('services.transcript_processor.OpenAIProvider'):
                with patch('services.transcript_processor.OpenAIModel'):
                    with patch('services.transcript_processor.Agent'):
                        processor = TranscriptProcessor()
                        
                        content = """
                        Artificial intelligence machine learning deep neural networks
                        technology programming python artificial intelligence algorithms
                        machine learning data science artificial intelligence
                        """
                        
                        keywords = processor.extract_keywords(content, 5)
                        
                        # Check keywords are extracted
                        assert len(keywords) > 0
                        assert "artificial" in keywords
                        assert "intelligence" in keywords
                        assert "machine" in keywords
                        assert "learning" in keywords
                        
                        # Check stop words are filtered
                        assert "the" not in keywords
                        assert "and" not in keywords
                        assert "to" not in keywords
    
    def test_tone_determination(self):
        """Test basic tone determination."""
        with patch('services.transcript_processor.settings') as mock_settings:
            mock_settings.openai_api_key = "test_key"
            
            with patch('services.transcript_processor.OpenAIProvider'):
                with patch('services.transcript_processor.OpenAIModel'):
                    with patch('services.transcript_processor.Agent'):
                        processor = TranscriptProcessor()
                        
                        # Test positive tone
                        positive_content = "This is amazing! Fantastic results! Great work! Excellent progress!"
                        assert processor.determine_basic_tone(positive_content) == "positive"
                        
                        # Test professional tone
                        professional_content = "Our research methodology framework implementation optimization strategy analysis"
                        assert processor.determine_basic_tone(professional_content) == "professional"
                        
                        # Test casual tone
                        casual_content = "Hey guys! This is so cool and fun! Epic stuff folks!"
                        assert processor.determine_basic_tone(casual_content) == "casual"
    
    def test_reading_time_estimation(self):
        """Test reading time estimation."""
        with patch('services.transcript_processor.settings') as mock_settings:
            mock_settings.openai_api_key = "test_key"
            
            with patch('services.transcript_processor.OpenAIProvider'):
                with patch('services.transcript_processor.OpenAIModel'):
                    with patch('services.transcript_processor.Agent'):
                        processor = TranscriptProcessor()
                        
                        # Test with known word count
                        content = " ".join(["word"] * 200)  # 200 words
                        reading_time = processor.estimate_reading_time(content)
                        
                        # Should be approximately 60 seconds (200 words / 200 WPM * 60)
                        assert 55 <= reading_time <= 65
    
    def test_basic_analysis_creation(self):
        """Test basic analysis when AI fails."""
        transcript = VideoTranscript(
            content="This is a comprehensive tutorial about artificial intelligence and machine learning applications in modern technology."
        )
        
        with patch('services.transcript_processor.settings') as mock_settings:
            mock_settings.openai_api_key = "test_key"
            
            with patch('services.transcript_processor.OpenAIProvider'):
                with patch('services.transcript_processor.OpenAIModel'):
                    with patch('services.transcript_processor.Agent'):
                        processor = TranscriptProcessor()
                        
                        analysis = processor._create_basic_analysis(transcript.content, transcript)
                        
                        assert isinstance(analysis, TranscriptAnalysis)
                        assert analysis.word_count > 0
                        assert len(analysis.keywords) > 0
                        assert analysis.tone in ["professional", "casual", "positive", "serious", "neutral"]
                        assert analysis.sentiment == "neutral"
                        assert analysis.estimated_reading_time > 0


def run_ai_service_tests():
    """Run all AI service tests."""
    print("🧪 Running AI Service Tests...\n")
    
    # Test ContentGeneratorService
    print("Testing ContentGeneratorService...")
    try:
        test_service = TestContentGeneratorService()
        test_service.test_service_initialization()
        test_service.test_base_system_prompt()
        test_service.test_platform_prompt_building()
        test_service.test_fallback_response_parsing()
        print("✅ ContentGeneratorService Tests - PASSED\n")
    except Exception as e:
        print(f"❌ ContentGeneratorService Tests - FAILED: {e}\n")
        return False
    
    # Test PlatformAgentManager
    print("Testing PlatformAgentManager...")
    try:
        test_manager = TestPlatformAgentManager()
        test_manager.test_agent_manager_initialization()
        test_manager.test_youtube_agent_prompts()
        test_manager.test_instagram_agent_prompts()
        test_manager.test_twitter_agent_character_limit()
        print("✅ PlatformAgentManager Tests - PASSED\n")
    except Exception as e:
        print(f"❌ PlatformAgentManager Tests - FAILED: {e}\n")
        return False
    
    # Test TranscriptProcessor
    print("Testing TranscriptProcessor...")
    try:
        test_processor = TestTranscriptProcessor()
        test_processor.test_transcript_cleaning()
        test_processor.test_keyword_extraction()
        test_processor.test_tone_determination()
        test_processor.test_reading_time_estimation()
        test_processor.test_basic_analysis_creation()
        print("✅ TranscriptProcessor Tests - PASSED\n")
    except Exception as e:
        print(f"❌ TranscriptProcessor Tests - FAILED: {e}\n")
        return False
    
    print("🎉 All AI Service Tests PASSED!")
    print("✅ Task 4.1: Base AI Service Setup - COMPLETE")
    print("✅ Task 4.2: Platform-Specific AI Agents - COMPLETE") 
    print("✅ Task 4.3: Transcript Processing Service - COMPLETE")
    return True


if __name__ == "__main__":
    success = run_ai_service_tests()
    if not success:
        exit(1)

================
File: app/tests/test_api_endpoints.py
================
"""
Tests for simplified API endpoints.
"""
import sys
from pathlib import Path

# Add the parent directory to Python path
parent_dir = Path(__file__).parent.parent
sys.path.insert(0, str(parent_dir))

import pytest
from fastapi.testclient import TestClient
from pydantic_ai import models
from pydantic_ai.models.test import TestModel
from models.platform_rules import PlatformType
from models.content import VideoTranscript, PlatformContent
from main import app

# Configure Pydantic AI for testing
models.ALLOW_MODEL_REQUESTS = False

# Create test client
client = TestClient(app)


class TestAPIEndpoints:
    """Test simplified API endpoints for content generation."""
    
    def test_root_endpoint(self):
        """Test the root endpoint returns correct information."""
        response = client.get("/")
        assert response.status_code == 200
        
        data = response.json()
        assert "message" in data
        assert "supported_platforms" in data
        assert "api_endpoints" in data
        assert len(data["supported_platforms"]) == 7
    
    def test_get_supported_platforms(self):
        """Test getting supported platforms list."""
        response = client.get("/api/v1/platforms")
        assert response.status_code == 200
        
        data = response.json()
        assert "platforms" in data
        assert "total_supported" in data
        assert data["total_supported"] == 7
        
        # Check that all expected platforms are present
        expected_platforms = ["youtube", "instagram", "facebook", "tiktok", "x_twitter", "linkedin", "twitch"]
        for platform in expected_platforms:
            assert platform in data["platforms"]
            platform_info = data["platforms"][platform]
            assert "name" in platform_info
            assert "title_max_length" in platform_info
            assert "tag_range" in platform_info
    
    def test_get_platform_rules_valid_platform(self):
        """Test getting rules for a valid platform."""
        response = client.get("/api/v1/platforms/youtube/rules")
        assert response.status_code == 200
        
        data = response.json()
        assert data["platform"] == "youtube"
        assert "rules" in data
        assert "special_requirements" in data
        
        rules = data["rules"]
        assert "title_max_length" in rules
        assert "tag_min_count" in rules
        assert "tag_max_count" in rules
        assert rules["title_max_length"] == 100
        assert rules["tag_min_count"] == 10
        assert rules["tag_max_count"] == 15
        
        # Check special requirements
        assert isinstance(data["special_requirements"], list)
        assert len(data["special_requirements"]) > 0
    
    def test_get_platform_rules_invalid_platform(self):
        """Test getting rules for an invalid platform."""
        response = client.get("/api/v1/platforms/invalid_platform/rules")
        assert response.status_code == 404
        
        data = response.json()
        assert "detail" in data
        assert "not supported" in data["detail"]
    
    def test_generate_single_platform_success(self):
        """Test successful single platform content generation using TestModel."""
        from services.orchestrator import get_content_orchestrator
        
        orchestrator = get_content_orchestrator()
        
        # Create custom test output
        test_output = """Title: AI Tutorial: Complete Guide
Tags: #AI, #Tutorial, #MachineLearning, #Python, #Programming, #Education, #Technology, #Coding, #DataScience, #Development, #Learning, #Tech"""
        
        with orchestrator.agent.override(model=TestModel(custom_output_text=test_output)):
            request_data = {
                "transcript": {
                    "content": "This is a comprehensive tutorial about artificial intelligence and machine learning."
                }
            }
            
            response = client.post("/api/v1/generate/youtube", json=request_data)
            assert response.status_code == 200
            
            data = response.json()
            assert data["platform"] == "youtube"
            assert "content" in data
            assert data["validation_passed"] in [True, False]
            assert "processing_time_seconds" in data
    
    def test_generate_single_platform_invalid_platform(self):
        """Test single platform generation with invalid platform."""
        request_data = {
            "transcript": {
                "content": "This is a test transcript."
            }
        }
        
        response = client.post("/api/v1/generate/invalid_platform", json=request_data)
        assert response.status_code == 404
        
        data = response.json()
        assert "detail" in data
        assert "not supported" in data["detail"]
    
    def test_generate_single_platform_short_transcript(self):
        """Test single platform generation with too short transcript."""
        request_data = {
            "transcript": {
                "content": "Short"
            }
        }
        
        response = client.post("/api/v1/generate/youtube", json=request_data)
        assert response.status_code == 422  # Pydantic validation error
        
        data = response.json()
        assert "detail" in data
    
    def test_validate_existing_content_valid(self):
        """Test validation of existing content."""
        content_data = {
            "platform": "youtube",
            "title": "Great AI Tutorial",
            "tags": ["#AI", "#tutorial", "#tech", "#programming", "#python",
                    "#education", "#learning", "#code", "#development", "#beginner"],
            "confidence_score": 0.9
        }
        
        response = client.post("/api/v1/validate/youtube", json=content_data)
        assert response.status_code == 200
        
        data = response.json()
        assert data["platform"] == "youtube"
        assert "is_valid" in data
        assert "quality_score" in data
        assert "issues" in data
        assert "suggestions" in data
    
    def test_validate_existing_content_platform_mismatch(self):
        """Test validation with platform mismatch."""
        content_data = {
            "platform": "instagram",  # Different from URL
            "title": "Test Title",
            "tags": ["#test"],
            "confidence_score": 0.8
        }
        
        response = client.post("/api/v1/validate/youtube", json=content_data)
        assert response.status_code == 400
        
        data = response.json()
        assert "detail" in data
        assert "doesn't match" in data["detail"]
    
    def test_health_check_healthy(self):
        """Test health check endpoint when services are healthy."""
        response = client.get("/api/v1/health")
        assert response.status_code == 200
        
        data = response.json()
        assert data["status"] == "healthy"
        assert "services" in data
        assert "supported_platforms" in data


def run_api_tests():
    """Run all API endpoint tests."""
    print("🧪 Running Simplified API Endpoint Tests...\n")
    
    try:
        test_api = TestAPIEndpoints()
        
        # Test basic endpoints
        print("Testing basic endpoints...")
        test_api.test_root_endpoint()
        test_api.test_get_supported_platforms()
        test_api.test_get_platform_rules_valid_platform()
        test_api.test_get_platform_rules_invalid_platform()
        print("✅ Basic endpoint tests - PASSED\n")
        
        # Test single platform generation
        print("Testing content generation...")
        test_api.test_generate_single_platform_success()
        test_api.test_generate_single_platform_invalid_platform()
        test_api.test_generate_single_platform_short_transcript()
        print("✅ Content generation tests - PASSED\n")
        
        # Test validation
        print("Testing content validation...")
        test_api.test_validate_existing_content_valid()
        test_api.test_validate_existing_content_platform_mismatch()
        print("✅ Content validation tests - PASSED\n")
        
        # Test health check
        print("Testing health check...")
        test_api.test_health_check_healthy()
        print("✅ Health check tests - PASSED\n")
        
        print("🎉 All Simplified API Endpoint Tests PASSED!")
        return True
        
    except Exception as e:
        print(f"❌ API Endpoint Tests - FAILED: {e}")
        return False


if __name__ == "__main__":
    success = run_api_tests()
    if not success:
        exit(1)

================
File: app/tests/test_config.py
================
"""
Test script to verify OpenAI API connectivity and configuration setup.
"""
import sys
import os
from pathlib import Path

# Add the parent directory to Python path so we can import from app
parent_dir = Path(__file__).parent.parent
sys.path.insert(0, str(parent_dir))

from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
from pydantic_ai.providers.openai import OpenAIProvider
from config import settings


def test_openai_connection():
    """Test basic OpenAI connectivity with a simple ping/test call."""
    try:
        # Create OpenAI model instance
        model = OpenAIModel('gpt-4o', provider=OpenAIProvider(api_key=settings.openai_api_key))
        
        # Create a simple agent for testing
        agent = Agent(model=model)
        
        # Test with a simple prompt using sync method
        result = agent.run_sync("Say 'Hello, OpenAI connection successful!'")
        
        print("✅ OpenAI API Connection Test PASSED")
        print(f"Response: {result.output}")
        return True
        
    except Exception as e:
        print("❌ OpenAI API Connection Test FAILED")
        print(f"Error: {str(e)}")
        return False


def test_settings_load():
    """Test that settings are loaded correctly."""
    try:
        print("🔧 Testing Settings Configuration...")
        print(f"Debug Mode: {settings.debug}")
        print(f"Log Level: {settings.log_level}")
        print(f"API Host: {settings.api_host}")
        print(f"API Port: {settings.api_port}")
        
        # Check if OpenAI API key is loaded (without exposing it)
        if settings.openai_api_key and len(settings.openai_api_key) > 10:
            print("✅ OpenAI API Key loaded successfully")
        else:
            print("❌ OpenAI API Key not found or invalid")
            return False
            
        print("✅ Settings Configuration Test PASSED")
        return True
        
    except Exception as e:
        print("❌ Settings Configuration Test FAILED")
        print(f"Error: {str(e)}")
        return False


if __name__ == "__main__":
    print("🚀 Starting Configuration Tests...\n")
    
    # Test settings configuration
    settings_ok = test_settings_load()
    print()
    
    if settings_ok:
        # Test OpenAI connection
        connection_ok = test_openai_connection()
        
        if connection_ok:
            print("\n🎉 All tests passed! Configuration is ready.")
        else:
            print("\n⚠️  Settings loaded but OpenAI connection failed.")
    else:
        print("\n⚠️  Settings configuration failed. Please check your .env file.")

================
File: app/tests/test_models.py
================
"""
Tests for data models to validate model instantiation and field constraints.
"""
import sys
from pathlib import Path

# Add the parent directory to Python path
parent_dir = Path(__file__).parent.parent
sys.path.insert(0, str(parent_dir))

import pytest
from datetime import datetime
from pydantic import ValidationError
from models.platform_rules import (
    PlatformRules, PlatformType, ContentStyle, 
    YouTubeRules, InstagramRules, FacebookRules, TikTokRules,
    XTwitterRules, LinkedInRules, TwitchRules,
    get_platform_rules, get_all_platforms, PLATFORM_RULES
)
from models.content import (
    VideoTranscript, GeneratedContent, PlatformContent,
    BatchGenerationRequest, BatchGenerationResponse,
    ContentGenerationOptions
)


class TestPlatformRules:
    """Test platform configuration models."""
    
    def test_platform_types_enum(self):
        """Test that all platform types are defined."""
        expected_platforms = {
            "youtube", "instagram", "facebook", "tiktok", 
            "x_twitter", "linkedin", "twitch"
        }
        actual_platforms = {p.value for p in PlatformType}
        assert actual_platforms == expected_platforms
    
    def test_youtube_rules(self):
        """Test YouTube platform rules."""
        rules = YouTubeRules()
        assert rules.platform == PlatformType.YOUTUBE
        assert rules.title_max_length == 100
        assert rules.tag_min_count == 10
        assert rules.tag_max_count == 15
        assert rules.content_style == ContentStyle.EDUCATIONAL_ENTERTAINMENT
        assert len(rules.style_guidelines) > 0
        assert len(rules.special_requirements) > 0
    
    def test_instagram_rules(self):
        """Test Instagram platform rules."""
        rules = InstagramRules()
        assert rules.platform == PlatformType.INSTAGRAM
        assert rules.title_max_length == 150
        assert rules.tag_min_count == 20
        assert rules.tag_max_count == 30
        assert rules.content_style == ContentStyle.VISUAL_LIFESTYLE
    
    def test_twitter_rules(self):
        """Test X/Twitter platform rules."""
        rules = XTwitterRules()
        assert rules.platform == PlatformType.X_TWITTER
        assert rules.title_max_length == 280
        assert rules.tag_min_count == 2
        assert rules.tag_max_count == 3
        assert rules.content_style == ContentStyle.CONCISE_TIMELY
    
    def test_get_platform_rules(self):
        """Test platform rules retrieval function."""
        youtube_rules = get_platform_rules(PlatformType.YOUTUBE)
        assert isinstance(youtube_rules, YouTubeRules)
        assert youtube_rules.platform == PlatformType.YOUTUBE
    
    def test_all_platforms_have_rules(self):
        """Test that all platforms have corresponding rules."""
        all_platforms = get_all_platforms()
        assert len(all_platforms) == 7
        
        for platform in all_platforms:
            rules = get_platform_rules(platform)
            assert rules.platform == platform
            assert rules.title_max_length > 0
            assert rules.tag_min_count >= 0
            assert rules.tag_max_count > rules.tag_min_count


class TestContentModels:
    """Test content generation models."""
    
    def test_video_transcript_valid(self):
        """Test valid video transcript creation."""
        transcript = VideoTranscript(
            content="This is a sample video transcript with enough content to be valid.",
            title="Sample Video",
            duration_seconds=120,
            language="en",
            video_category="educational"
        )
        assert transcript.content == "This is a sample video transcript with enough content to be valid."
        assert transcript.title == "Sample Video"
        assert transcript.duration_seconds == 120
        assert transcript.language == "en"
    
    def test_video_transcript_content_too_short(self):
        """Test video transcript with too short content."""
        with pytest.raises(ValidationError, match="String should have at least 10 characters"):
            VideoTranscript(content="short")
    
    def test_video_transcript_invalid_language(self):
        """Test video transcript with invalid language code."""
        with pytest.raises(ValidationError, match="Invalid language code format"):
            VideoTranscript(
                content="This is a valid transcript content.",
                language="invalid_lang_code"
            )
    
    def test_generated_content_valid(self):
        """Test valid generated content creation."""
        content = GeneratedContent(
            title="Amazing AI Tutorial",
            tags=["AI", "tutorial", "machine learning"],
            confidence_score=0.85
        )
        assert content.title == "Amazing AI Tutorial"
        assert len(content.tags) == 3
        assert all(tag.startswith('#') for tag in content.tags)
        assert content.confidence_score == 0.85
        assert isinstance(content.generation_timestamp, datetime)
    
    def test_generated_content_tag_formatting(self):
        """Test tag formatting in generated content."""
        content = GeneratedContent(
            title="Test Content",
            tags=["ai tutorial", "#machinelearning", "python programming"],
            confidence_score=0.9
        )
        # Tags should be cleaned and formatted
        expected_tags = ["#aitutorial", "#machinelearning", "#pythonprogramming"]
        assert content.tags == expected_tags
    
    def test_platform_content_validation(self):
        """Test platform content creation and validation."""
        content = PlatformContent(
            platform=PlatformType.YOUTUBE,
            title="Great AI Tutorial for Beginners",
            tags=["#AI", "#tutorial", "#beginners", "#machinelearning", "#python"],
            confidence_score=0.88
        )
        
        # Computed fields should calculate counts automatically
        assert content.character_count == len("Great AI Tutorial for Beginners")
        assert content.tag_count == 5
        assert content.platform == PlatformType.YOUTUBE
    
    def test_platform_content_rule_validation(self):
        """Test platform content validation against rules."""
        # Create content that violates YouTube rules
        content = PlatformContent(
            platform=PlatformType.YOUTUBE,
            title="This is a very long title that definitely exceeds the YouTube character limit for titles",
            tags=["#AI"],  # Too few tags for YouTube
            confidence_score=0.5
        )
        
        youtube_rules = get_platform_rules(PlatformType.YOUTUBE)
        is_valid = content.validate_against_platform_rules(youtube_rules)
        
        assert not is_valid
        assert not content.meets_requirements
        assert len(content.validation_notes) > 0
    
    def test_batch_generation_request(self):
        """Test batch generation request model."""
        transcript = VideoTranscript(content="Sample transcript content for testing batch generation.")
        
        request = BatchGenerationRequest(
            transcript=transcript,
            platforms=[PlatformType.YOUTUBE, PlatformType.INSTAGRAM, PlatformType.TIKTOK]
        )
        
        assert len(request.platforms) == 3
        assert PlatformType.YOUTUBE in request.platforms
        assert isinstance(request.transcript, VideoTranscript)
    
    def test_batch_generation_request_no_duplicates(self):
        """Test batch generation request removes duplicate platforms."""
        transcript = VideoTranscript(content="Sample transcript for duplicate platform test.")
        
        request = BatchGenerationRequest(
            transcript=transcript,
            platforms=[PlatformType.YOUTUBE, PlatformType.YOUTUBE, PlatformType.INSTAGRAM]
        )
        
        # Should remove duplicates
        assert len(request.platforms) == 2
        assert PlatformType.YOUTUBE in request.platforms
        assert PlatformType.INSTAGRAM in request.platforms
    
    def test_content_generation_options(self):
        """Test content generation options model."""
        options = ContentGenerationOptions(
            tone="energetic",
            include_emojis=True,
            target_audience="tech enthusiasts",
            keywords_to_include=["AI", "innovation"],
            keywords_to_avoid=["boring", "complicated"]
        )
        
        assert options.tone == "energetic"
        assert options.include_emojis is True
        assert options.target_audience == "tech enthusiasts"
        assert len(options.keywords_to_include) == 2
        assert len(options.keywords_to_avoid) == 2


def run_all_tests():
    """Run all model tests and report results."""
    print("🧪 Running Model Tests...\n")
    
    # Test platform rules
    print("Testing Platform Rules...")
    try:
        test_platform = TestPlatformRules()
        test_platform.test_platform_types_enum()
        test_platform.test_youtube_rules()
        test_platform.test_instagram_rules()
        test_platform.test_twitter_rules()
        test_platform.test_get_platform_rules()
        test_platform.test_all_platforms_have_rules()
        print("✅ Platform Rules Tests - PASSED\n")
    except Exception as e:
        print(f"❌ Platform Rules Tests - FAILED: {e}\n")
        return False
    
    # Test content models
    print("Testing Content Models...")
    try:
        test_content = TestContentModels()
        test_content.test_video_transcript_valid()
        test_content.test_generated_content_valid()
        test_content.test_generated_content_tag_formatting()
        test_content.test_platform_content_validation()
        test_content.test_batch_generation_request()
        test_content.test_batch_generation_request_no_duplicates()
        test_content.test_content_generation_options()
        print("✅ Content Models Tests - PASSED\n")
    except Exception as e:
        print(f"❌ Content Models Tests - FAILED: {e}\n")
        return False
    
    # Test validation edge cases
    print("Testing Validation Edge Cases...")
    try:
        # Test short transcript
        try:
            VideoTranscript(content="short")
        except ValidationError:
            pass  # Expected
        
        # Test invalid language code
        try:
            VideoTranscript(content="Valid transcript content", language="toolongcode")
        except ValidationError:
            pass  # Expected
        
        print("✅ Validation Edge Cases Tests - PASSED\n")
    except Exception as e:
        print(f"❌ Validation Edge Cases Tests - FAILED: {e}\n")
        return False
    
    print("🎉 All Model Tests PASSED!")
    print("✅ Task 2.1: Platform Configuration Models - COMPLETE")
    print("✅ Task 2.2: Content Generation Models - COMPLETE")
    return True


if __name__ == "__main__":
    success = run_all_tests()
    if not success:
        exit(1)

================
File: app/tests/test_phase5_services.py
================
"""
Tests for Phase 5 Core Business Logic services - simplified version.
Tests the simplified orchestrator and content validation services.
"""
import sys
from pathlib import Path

# Add the parent directory to Python path
parent_dir = Path(__file__).parent.parent
sys.path.insert(0, str(parent_dir))

import pytest
import asyncio
from unittest.mock import Mock, patch
from pydantic_ai import models
from pydantic_ai.models.test import TestModel
from models.platform_rules import PlatformType
from models.content import VideoTranscript, PlatformContent
from services.orchestrator import ContentOrchestrator
from services.content_validator import ContentValidator, ValidationSeverity, ValidationResult

# Configure Pydantic AI for testing
models.ALLOW_MODEL_REQUESTS = False

# Use pytest-asyncio for async tests
pytestmark = pytest.mark.asyncio


class TestContentOrchestrator:
    """Test simplified content generation orchestrator."""
    
    async def test_orchestrator_initialization(self):
        """Test that orchestrator initializes correctly."""
        orchestrator = ContentOrchestrator()
        
        assert orchestrator.model_name == "gpt-4o"
        assert orchestrator.agent is not None
    
    async def test_generate_content_success(self):
        """Test successful content generation using TestModel."""
        transcript = VideoTranscript(
            content="Learn about AI and machine learning in this comprehensive tutorial."
        )
        
        orchestrator = ContentOrchestrator()
        
        # Create custom TestModel output that will parse correctly
        test_output = """Title: Complete AI Tutorial: Master Machine Learning
Tags: #AI, #MachineLearning, #Tutorial, #Python, #Programming, #Education, #Technology, #Coding, #DataScience, #Development, #Learning, #Tech"""
        
        test_model = TestModel(custom_output_text=test_output)
        
        # Override the agent with TestModel
        with orchestrator.agent.override(model=test_model):
            content = await orchestrator.generate_content(PlatformType.YOUTUBE, transcript)
            
            assert isinstance(content, PlatformContent)
            assert content.platform == PlatformType.YOUTUBE
            assert "AI Tutorial" in content.title
            assert len(content.tags) >= 10  # YouTube requires 10-15 tags
            assert content.confidence_score > 0.5
    
    async def test_generate_content_fallback(self):
        """Test fallback content generation when AI fails."""
        transcript = VideoTranscript(
            content="Test transcript for error handling."
        )
        
        orchestrator = ContentOrchestrator()
        
        # Mock the agent to raise an exception
        with patch.object(orchestrator.agent, 'run', side_effect=Exception("AI service error")):
            content = await orchestrator.generate_content(PlatformType.INSTAGRAM, transcript)
            
            # Should return fallback content
            assert isinstance(content, PlatformContent)
            assert content.platform == PlatformType.INSTAGRAM
            assert content.title == "Instagram Post"
            assert len(content.tags) >= 1
            assert content.confidence_score < 0.5  # Low confidence for fallback
    
    async def test_generate_content_different_platforms(self):
        """Test content generation for different platforms."""
        transcript = VideoTranscript(
            content="This video covers web development with modern frameworks."
        )
        
        orchestrator = ContentOrchestrator()
        
        # Test outputs for different platforms
        platform_outputs = {
            PlatformType.YOUTUBE: "Title: Web Development Tutorial: Modern Frameworks Guide\nTags: #WebDevelopment, #Programming, #JavaScript, #React, #Vue, #Angular, #Tutorial, #Coding, #Frontend, #Backend, #FullStack, #Tech",
            PlatformType.INSTAGRAM: "Title: Modern Web Dev Magic ✨🚀\nTags: " + ", ".join([f"#tag{i}" for i in range(1, 26)]),
            PlatformType.TIKTOK: "Title: Web Dev in 60 seconds! 🔥\nTags: #WebDev, #Coding, #TechTok, #Programming"
        }
        
        for platform, output in platform_outputs.items():
            test_model = TestModel(custom_output_text=output)
            
            with orchestrator.agent.override(model=test_model):
                content = await orchestrator.generate_content(platform, transcript)
                
                assert content.platform == platform
                assert len(content.title) > 0
                assert len(content.tags) > 0


class TestContentValidator:
    """Test content validation service."""
    
    def test_validator_initialization(self):
        """Test that validator initializes correctly."""
        validator = ContentValidator()
        assert validator.quality_weights is not None
        assert len(validator.quality_weights) == 5
    
    def test_validate_content_success(self):
        """Test successful content validation."""
        content = PlatformContent(
            platform=PlatformType.YOUTUBE,
            title="Great AI Tutorial for Beginners",
            tags=["#AI", "#tutorial", "#programming", "#machinelearning", 
                  "#python", "#development", "#coding", "#tech", "#beginners", "#education"],
            confidence_score=0.9
        )
        
        validator = ContentValidator()
        result = validator.validate_content(content)
        
        assert isinstance(result, ValidationResult)
        assert result.platform == PlatformType.YOUTUBE
        assert result.content == content
        # Should be valid since it meets YouTube requirements
        assert result.is_valid is True
        assert result.score > 70  # Should have a good score
    
    def test_validate_content_character_limit_violation(self):
        """Test validation with character limit violation."""
        content = PlatformContent(
            platform=PlatformType.YOUTUBE,
            title="This is an extremely long title that definitely exceeds the YouTube character limit for titles and should trigger a validation error",  # >100 chars
            tags=["#AI"] * 12,  # Valid tag count
            confidence_score=0.8
        )
        
        validator = ContentValidator()
        result = validator.validate_content(content)
        
        assert result.is_valid is False
        assert any(issue.severity == ValidationSeverity.ERROR for issue in result.issues)
        # Check for the actual error message
        assert any("exceeds maximum length" in issue.message.lower() for issue in result.issues)
    
    def test_validate_content_tag_count_issues(self):
        """Test validation with tag count issues."""
        # Too few tags for YouTube
        content = PlatformContent(
            platform=PlatformType.YOUTUBE,
            title="Valid Title",
            tags=["#AI", "#tutorial"],  # Only 2 tags, YouTube needs 10-15
            confidence_score=0.8
        )
        
        validator = ContentValidator()
        result = validator.validate_content(content)
        
        assert result.is_valid is False
        assert any(issue.field == "tags" and issue.severity == ValidationSeverity.ERROR 
                  for issue in result.issues)
        assert any("few tags" in issue.message.lower() for issue in result.issues)
    
    def test_validate_platform_specific_linkedin(self):
        """Test LinkedIn-specific validation (professional tone)."""
        content = PlatformContent(
            platform=PlatformType.LINKEDIN,
            title="Hey guys! This is awesome! OMG check this out!",  # Too casual for LinkedIn
            tags=["#professional", "#business", "#career"],
            confidence_score=0.8
        )
        
        validator = ContentValidator()
        result = validator.validate_content(content)
        
        # Should have warnings about casual language
        assert any(issue.field == "tone" for issue in result.issues)
        assert any("casual" in issue.message.lower() for issue in result.issues)
    
    def test_validate_platform_specific_twitter(self):
        """Test X/Twitter-specific validation (total character limit)."""
        content = PlatformContent(
            platform=PlatformType.X_TWITTER,
            title="This is a very long tweet that when combined with hashtags will definitely exceed the 280 character limit that Twitter enforces for all content including both the main text and any hashtags that are included in the post content",  # Long title
            tags=["#verylonghashtag", "#anotherlonghashtag", "#yetanotherlonghashtag"],  # Added third tag to exceed limit
            confidence_score=0.8
        )
        
        validator = ContentValidator()
        result = validator.validate_content(content)
        
        # Should fail due to total character limit
        assert result.is_valid is False
        assert any("total" in issue.message.lower() and ("character" in issue.message.lower() or "content" in issue.message.lower()) 
                  for issue in result.issues)


async def run_phase5_tests():
    """Run all Phase 5 service tests."""
    print("🧪 Running Phase 5 Simplified Tests...\n")
    
    # Test ContentOrchestrator
    print("Testing ContentOrchestrator...")
    try:
        test_orchestrator = TestContentOrchestrator()
        await test_orchestrator.test_orchestrator_initialization()
        await test_orchestrator.test_generate_content_success()
        await test_orchestrator.test_generate_content_fallback()
        await test_orchestrator.test_generate_content_different_platforms()
        print("✅ ContentOrchestrator Tests - PASSED\n")
    except Exception as e:
        print(f"❌ ContentOrchestrator Tests - FAILED: {e}\n")
        return False
    
    # Test ContentValidator
    print("Testing ContentValidator...")
    try:
        test_validator = TestContentValidator()
        test_validator.test_validator_initialization()
        test_validator.test_validate_content_success()
        test_validator.test_validate_content_character_limit_violation()
        test_validator.test_validate_content_tag_count_issues()
        test_validator.test_validate_platform_specific_linkedin()
        test_validator.test_validate_platform_specific_twitter()
        print("✅ ContentValidator Tests - PASSED\n")
    except Exception as e:
        print(f"❌ ContentValidator Tests - FAILED: {e}\n")
        return False
    
    print("🎉 All Phase 5 Simplified Tests PASSED!")
    return True


if __name__ == "__main__":
    success = asyncio.run(run_phase5_tests())
    if not success:
        exit(1)

================
File: app/tests/test_platform_rules.py
================
"""
Comprehensive tests for platform-specific content rules and validation.
Tests character limits, tag constraints, and content style enforcement.
"""
import sys
from pathlib import Path

# Add the parent directory to Python path
parent_dir = Path(__file__).parent.parent
sys.path.insert(0, str(parent_dir))

import pytest
from models.platform_rules import (
    PlatformType, get_platform_rules, 
    YouTubeRules, InstagramRules, FacebookRules, TikTokRules,
    XTwitterRules, LinkedInRules, TwitchRules
)
from models.content import PlatformContent


class TestYouTubeRules:
    """Test YouTube platform-specific content rules."""
    
    def setup_method(self):
        """Set up test fixtures."""
        self.rules = YouTubeRules()
        
    def test_youtube_character_limits(self):
        """Test YouTube title character limit enforcement."""
        # Valid title (within 100 characters)
        valid_content = PlatformContent(
            platform=PlatformType.YOUTUBE,
            title="How to Build AI Applications: Complete Tutorial for Beginners in 2024",  # 70 chars
            tags=["#AI", "#tutorial", "#programming", "#machinelearning", 
                  "#python", "#development", "#coding", "#tech", "#beginners", "#2024"],
            confidence_score=0.9
        )
        
        assert valid_content.character_count <= self.rules.title_max_length
        assert valid_content.validate_against_platform_rules(self.rules) == True
        
        # Invalid title (exceeds 100 characters)
        invalid_content = PlatformContent(
            platform=PlatformType.YOUTUBE,
            title="This is an extremely long YouTube title that definitely exceeds the 100 character limit for YouTube videos",  # 107 chars
            tags=["#AI"] * 12,  # Valid tag count
            confidence_score=0.8
        )
        
        assert invalid_content.character_count > self.rules.title_max_length
        assert invalid_content.validate_against_platform_rules(self.rules) == False
        assert any("exceeds maximum length" in note for note in invalid_content.validation_notes)
    
    def test_youtube_tag_count_constraints(self):
        """Test YouTube tag count requirements (10-15 tags)."""
        # Valid tag count (12 tags)
        valid_content = PlatformContent(
            platform=PlatformType.YOUTUBE,
            title="Great AI Tutorial",
            tags=["#AI", "#tutorial", "#programming", "#machinelearning", 
                  "#python", "#development", "#coding", "#tech", "#beginners", 
                  "#education", "#learning", "#software"],
            confidence_score=0.9
        )
        
        assert self.rules.tag_min_count <= valid_content.tag_count <= self.rules.tag_max_count
        assert valid_content.validate_against_platform_rules(self.rules) == True
        
        # Too few tags (8 tags)
        too_few_tags = PlatformContent(
            platform=PlatformType.YOUTUBE,
            title="AI Tutorial",
            tags=["#AI", "#tutorial", "#programming", "#machinelearning", 
                  "#python", "#development", "#coding", "#tech"],
            confidence_score=0.8
        )
        
        assert too_few_tags.tag_count < self.rules.tag_min_count
        assert too_few_tags.validate_against_platform_rules(self.rules) == False
        assert any("Too few tags" in note for note in too_few_tags.validation_notes)
        
        # Too many tags (18 tags)
        too_many_tags = PlatformContent(
            platform=PlatformType.YOUTUBE,
            title="AI Tutorial",
            tags=["#AI", "#tutorial", "#programming", "#machinelearning", 
                  "#python", "#development", "#coding", "#tech", "#beginners",
                  "#education", "#learning", "#software", "#data", "#science",
                  "#analytics", "#deep", "#neural", "#networks"],
            confidence_score=0.8
        )
        
        assert too_many_tags.tag_count > self.rules.tag_max_count
        assert too_many_tags.validate_against_platform_rules(self.rules) == False
        assert any("Too many tags" in note for note in too_many_tags.validation_notes)
    
    def test_youtube_content_style_guidelines(self):
        """Test YouTube content style requirements."""
        assert "educational" in str(self.rules.content_style).lower()
        assert "entertainment" in str(self.rules.content_style).lower()
        assert len(self.rules.style_guidelines) >= 3
        assert len(self.rules.special_requirements) >= 2
        
        # Check key guidelines are present
        guidelines_text = " ".join(self.rules.style_guidelines).lower()
        assert "seo" in guidelines_text or "search" in guidelines_text
        assert "trending" in guidelines_text or "keyword" in guidelines_text


class TestInstagramRules:
    """Test Instagram platform-specific content rules."""
    
    def setup_method(self):
        """Set up test fixtures."""
        self.rules = InstagramRules()
    
    def test_instagram_character_limits(self):
        """Test Instagram caption character limit (150 chars)."""
        # Valid caption
        valid_content = PlatformContent(
            platform=PlatformType.INSTAGRAM,
            title="Amazing sunset vibes! 🌅 Perfect way to end the day with nature's beauty. What's your favorite time to watch sunsets?",  # 128 chars
            tags=["#sunset", "#nature", "#photography", "#vibes", "#golden",
                  "#beautiful", "#peaceful", "#evening", "#sky", "#colors"] * 3,  # 30 tags
            confidence_score=0.9
        )
        
        assert valid_content.character_count <= self.rules.title_max_length
        assert valid_content.validate_against_platform_rules(self.rules) == True
    
    def test_instagram_hashtag_requirements(self):
        """Test Instagram hashtag requirements (20-30 hashtags)."""
        # Valid hashtag count (25 tags)
        valid_content = PlatformContent(
            platform=PlatformType.INSTAGRAM,
            title="Beautiful sunset!",
            tags=["#sunset", "#nature", "#photography", "#vibes", "#golden",
                  "#beautiful", "#peaceful", "#evening", "#sky", "#colors",
                  "#landscape", "#travel", "#wanderlust", "#explore", "#adventure",
                  "#outdoor", "#scenic", "#breathtaking", "#amazing", "#stunning",
                  "#picoftheday", "#photooftheday", "#instagood", "#love", "#life"],
            confidence_score=0.9
        )
        
        assert self.rules.tag_min_count <= valid_content.tag_count <= self.rules.tag_max_count
        assert valid_content.validate_against_platform_rules(self.rules) == True
    
    def test_instagram_content_style(self):
        """Test Instagram visual-lifestyle content style."""
        assert "visual" in str(self.rules.content_style).lower()
        assert "lifestyle" in str(self.rules.content_style).lower()
        
        guidelines_text = " ".join(self.rules.style_guidelines).lower()
        assert "visual" in guidelines_text
        assert "hashtag" in guidelines_text


class TestFacebookRules:
    """Test Facebook platform-specific content rules."""
    
    def setup_method(self):
        """Set up test fixtures."""
        self.rules = FacebookRules()
    
    def test_facebook_character_limits(self):
        """Test Facebook post character limit (255 chars)."""
        # Valid post (200 chars)
        valid_content = PlatformContent(
            platform=PlatformType.FACEBOOK,
            title="Join our amazing community of learners! We're excited to share knowledge, support each other, and grow together. What topics would you like to explore with us?",  # 168 chars
            tags=["#community", "#learning", "#growth", "#support"],
            confidence_score=0.9
        )
        
        assert valid_content.character_count <= self.rules.title_max_length
        assert valid_content.validate_against_platform_rules(self.rules) == True
    
    def test_facebook_minimal_hashtags(self):
        """Test Facebook minimal hashtag approach (3-5 hashtags)."""
        # Valid hashtag count (4 tags)
        valid_content = PlatformContent(
            platform=PlatformType.FACEBOOK,
            title="Great community event!",
            tags=["#community", "#event", "#networking", "#growth"],
            confidence_score=0.9
        )
        
        assert self.rules.tag_min_count <= valid_content.tag_count <= self.rules.tag_max_count
        assert valid_content.validate_against_platform_rules(self.rules) == True


class TestTikTokRules:
    """Test TikTok platform-specific content rules."""
    
    def setup_method(self):
        """Set up test fixtures."""
        self.rules = TikTokRules()
    
    def test_tiktok_character_limits(self):
        """Test TikTok caption character limit (150 chars)."""
        # Valid caption with trendy language
        valid_content = PlatformContent(
            platform=PlatformType.TIKTOK,
            title="This AI hack is absolutely mind-blowing! 🤯 You won't believe how easy it is to automate your workflow ✨",  # 104 chars
            tags=["#AIhack", "#productivity", "#trending"],
            confidence_score=0.9
        )
        
        assert valid_content.character_count <= self.rules.title_max_length
        assert valid_content.validate_against_platform_rules(self.rules) == True
    
    def test_tiktok_trending_focus(self):
        """Test TikTok trending and Gen-Z focused content style."""
        assert "trend" in str(self.rules.content_style).lower()
        
        guidelines_text = " ".join(self.rules.style_guidelines).lower()
        assert "trend" in guidelines_text
        assert "gen-z" in guidelines_text or "viral" in guidelines_text


class TestXTwitterRules:
    """Test X (Twitter) platform-specific content rules."""
    
    def setup_method(self):
        """Set up test fixtures."""
        self.rules = XTwitterRules()
    
    def test_twitter_total_character_limit(self):
        """Test X/Twitter total character limit including hashtags (280 chars)."""
        # Valid tweet with hashtags within limit
        valid_content = PlatformContent(
            platform=PlatformType.X_TWITTER,
            title="Just discovered an amazing AI tool that's revolutionizing content creation! The possibilities are endless when technology meets creativity. What's your favorite AI application?",  # 182 chars
            tags=["#AI", "#tech"],  # ~8 additional chars with spaces
            confidence_score=0.9
        )
        
        # Validate against special Twitter rule (total character limit)
        is_valid = valid_content.validate_against_platform_rules(self.rules)
        total_chars = len(valid_content.title) + sum(len(tag) + 1 for tag in valid_content.tags)
        
        assert total_chars <= self.rules.title_max_length
        assert is_valid == True
    
    def test_twitter_hashtag_integration(self):
        """Test X/Twitter hashtag integration requirements."""
        guidelines_text = " ".join(self.rules.style_guidelines).lower()
        assert "hashtag" in guidelines_text
        assert "integrated" in guidelines_text or "conversation" in guidelines_text


class TestLinkedInRules:
    """Test LinkedIn platform-specific content rules."""
    
    def setup_method(self):
        """Set up test fixtures."""
        self.rules = LinkedInRules()
    
    def test_linkedin_professional_tone(self):
        """Test LinkedIn professional content requirements."""
        # Valid professional post
        valid_content = PlatformContent(
            platform=PlatformType.LINKEDIN,
            title="Excited to share insights from our latest industry research on AI adoption in enterprise environments.",  # 109 chars
            tags=["#AI", "#enterprise", "#research", "#innovation"],
            confidence_score=0.9
        )
        
        assert valid_content.character_count <= self.rules.title_max_length
        assert valid_content.validate_against_platform_rules(self.rules) == True
    
    def test_linkedin_professional_style(self):
        """Test LinkedIn professional content style requirements."""
        assert "professional" in str(self.rules.content_style).lower()
        
        guidelines_text = " ".join(self.rules.style_guidelines).lower()
        assert "professional" in guidelines_text
        assert "industry" in guidelines_text or "thought" in guidelines_text


class TestTwitchRules:
    """Test Twitch platform-specific content rules."""
    
    def setup_method(self):
        """Set up test fixtures."""
        self.rules = TwitchRules()
    
    def test_twitch_gaming_focus(self):
        """Test Twitch gaming and streaming content requirements."""
        # Valid gaming stream title
        valid_content = PlatformContent(
            platform=PlatformType.TWITCH,
            title="Epic AI vs Human showdown! Come watch the ultimate coding battle live!",  # 75 chars
            tags=["#gaming", "#AI", "#coding", "#live", "#battle"],
            confidence_score=0.9
        )
        
        assert valid_content.character_count <= self.rules.title_max_length
        assert valid_content.validate_against_platform_rules(self.rules) == True
    
    def test_twitch_gaming_community_style(self):
        """Test Twitch gaming community content style."""
        assert "gaming" in str(self.rules.content_style).lower()
        
        guidelines_text = " ".join(self.rules.style_guidelines).lower()
        assert "gaming" in guidelines_text
        assert "community" in guidelines_text or "interactive" in guidelines_text


def run_platform_tests():
    """Run all platform-specific rule tests."""
    print("🧪 Running Platform-Specific Rule Tests...\n")
    
    test_classes = [
        TestYouTubeRules,
        TestInstagramRules, 
        TestFacebookRules,
        TestTikTokRules,
        TestXTwitterRules,
        TestLinkedInRules,
        TestTwitchRules
    ]
    
    for test_class in test_classes:
        platform_name = test_class.__name__.replace("Test", "").replace("Rules", "")
        print(f"Testing {platform_name}...")
        
        try:
            test_instance = test_class()
            test_instance.setup_method()
            
            # Run all test methods
            for method_name in dir(test_instance):
                if method_name.startswith('test_'):
                    getattr(test_instance, method_name)()
            
            print(f"✅ {platform_name} Rules Tests - PASSED")
            
        except Exception as e:
            print(f"❌ {platform_name} Rules Tests - FAILED: {e}")
            return False
        
        print()
    
    print("🎉 All Platform-Specific Rule Tests PASSED!")
    print("✅ Phase 3: Platform-Specific Content Rules - COMPLETE")
    return True


if __name__ == "__main__":
    success = run_platform_tests()
    if not success:
        exit(1)

================
File: app/__init__.py
================
"""
Video Transcript to Social Media Content Generator
Main application package
"""

================
File: app/config.py
================
"""
Configuration module for the Video Transcript to Social Media Content Generator.
Handles environment variables and application settings.
"""
import os
from typing import Optional
from pydantic import Field, ConfigDict
from pydantic_settings import BaseSettings
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()


class Settings(BaseSettings):
    """Application settings loaded from environment variables."""
    
    # OpenAI Configuration
    openai_api_key: str = Field(..., env="OPENAI_API_KEY")
    
    # Application Configuration  
    debug: bool = Field(default=True, env="DEBUG")
    log_level: str = Field(default="INFO", env="LOG_LEVEL")
    
    # API Configuration
    api_host: str = Field(default="localhost", env="API_HOST")
    api_port: int = Field(default=8000, env="API_PORT")
    
    model_config = ConfigDict(env_file=".env", case_sensitive=False)


def get_settings() -> Settings:
    """Get application settings instance."""
    settings = Settings()
    # Ensure OpenAI API key is set in environment for Pydantic AI
    if settings.openai_api_key:
        os.environ["OPENAI_API_KEY"] = settings.openai_api_key
    return settings


# Global settings instance
settings = get_settings()

================
File: app/main.py
================
"""
FastAPI application main entry point for Video Transcript to Social Media Content Generator.
"""
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from config import settings
from routers.content_generation import router as content_router
from routers.audio_transcription import router as audio_router

# Create FastAPI application instance
app = FastAPI(
    title="Video Transcript to Social Media Content Generator",
    description="Generate platform-specific titles and tags from video transcripts using AI",
    version="1.0.0",
    debug=settings.debug
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include routers
app.include_router(content_router)
app.include_router(audio_router)


@app.get("/")
async def root():
    """Root endpoint for health check."""
    return {
        "message": "Video Transcript to Social Media Content Generator API",
        "status": "running",
        "version": "1.0.0",
        "supported_platforms": ["YouTube", "Instagram", "Facebook", "TikTok", "X (Twitter)", "LinkedIn", "Twitch"],
        "api_endpoints": {
            "platforms": "/api/v1/platforms",
            "generate": "/api/v1/generate/{platform}",
            "validate": "/api/v1/validate/{platform}",
            "platform_rules": "/api/v1/platforms/{platform}/rules",
            "health": "/api/v1/health",
            "docs": "/docs"
        }
    }


@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {"status": "healthy"}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host=settings.api_host,
        port=settings.api_port,
        reload=settings.debug
    )

================
File: docs/todos/title_gen.md
================
# TODO: Video Transcript to Social Media Content Generator

## Project Overview
Implement functionality to generate titles and tags for multiple social media platforms given a video transcript. The system will use OpenAI's models via Pydantic AI to generate platform-specific content following each platform's content length rules and style guidelines.

**Target Platforms:** YouTube, Instagram, Facebook, TikTok, X (Twitter), LinkedIn, Twitch

**Reference:** [Pydantic AI OpenAI Models](https://ai.pydantic.dev/models/openai/)

---

## 🏗️ **Phase 1: Project Foundation & Configuration**

- [x] **Task 1.1: Environment Setup**
  - Set up OpenAI API key configuration using environment variables
  - Create `.env` file template with required API keys
  - Configure Pydantic AI with OpenAI provider
  - Test basic OpenAI connectivity
  - **Testing**: Verify API connection with a simple ping/test call

- [x] **Task 1.2: Project Structure Setup**
  - Create core application structure in `/app` directory
  - Set up FastAPI application foundation
  - Create directory structure: `/models`, `/services`, `/routers`, `/config`, `/tests`
  - **Testing**: Verify FastAPI application starts successfully

---

## 📋 **Phase 2: Data Models & Platform Definitions**

- [x] **Task 2.1: Platform Configuration Models**
  - Create Pydantic models for platform-specific rules:
    - `PlatformRules` base model
    - Platform-specific models for each platform (YouTube, Instagram, Facebook, TikTok, X, LinkedIn, Twitch)
  - Define character limits, content style guidelines, and tag requirements per platform
  - **Testing**: Validate model instantiation and field constraints

- [x] **Task 2.2: Content Generation Models**
  - Create `VideoTranscript` input model
  - Create `GeneratedContent` output model with title and tags
  - Create `PlatformContent` model for platform-specific generated content
  - **Testing**: Validate model serialization/deserialization

---

## 🎯 **Phase 3: Platform-Specific Content Rules**

- [x] **Task 3.1: YouTube Content Rules**
  - Title: Max 100 characters, engaging and SEO-friendly
  - Tags: 10-15 relevant tags, trending keywords focus
  - Content style: Educational/entertainment balance
  - **Testing**: Validate character limits and tag count constraints

- [x] **Task 3.2: Instagram Content Rules**
  - Title: Max 150 characters (for captions), visually appealing
  - Tags: 20-30 hashtags, mix of popular and niche tags
  - Content style: Visual-first, engaging, lifestyle-focused
  - **Testing**: Validate hashtag formatting and character limits

- [x] **Task 3.3: Facebook Content Rules**
  - Title: Max 255 characters, engagement-focused
  - Tags: 3-5 relevant hashtags, not hashtag-heavy
  - Content style: Community-building, shareable content
  - **Testing**: Validate content length and engagement elements

- [x] **Task 3.4: TikTok Content Rules**
  - Title: Max 150 characters, trend-aware, catchy
  - Tags: 3-5 trending hashtags, viral potential
  - Content style: Gen-Z friendly, trend-focused
  - **Testing**: Validate trend keyword integration

- [x] **Task 3.5: X (Twitter) Content Rules**
  - Title: Max 280 characters total (including hashtags)
  - Tags: 2-3 hashtags integrated into text
  - Content style: Concise, timely, conversation-starting
  - **Testing**: Validate total character count including hashtags

- [x] **Task 3.6: LinkedIn Content Rules**
  - Title: Max 210 characters, professional tone
  - Tags: 3-5 professional/industry hashtags
  - Content style: Professional, thought-leadership focused
  - **Testing**: Validate professional tone and industry relevance

- [x] **Task 3.7: Twitch Content Rules**
  - Title: Max 140 characters, gaming/streaming focused
  - Tags: Gaming categories, community-focused tags
  - Content style: Gaming community, interactive content
  - **Testing**: Validate gaming terminology and community focus

---

## 🤖 **Phase 4: AI Content Generation Service**

- [x] **Task 4.1: Base AI Service Setup**
  - Create `ContentGeneratorService` using Pydantic AI
  - Configure OpenAI model (GPT-4o)
  - Implement base prompt engineering for content generation
  - **Testing**: Test basic AI response generation

- [x] **Task 4.2: Platform-Specific AI Agents**
  - Create separate AI agents for each platform
  - Implement platform-specific prompt engineering
  - Configure response formatting for each platform's requirements
  - **Testing**: Test each agent independently with sample transcripts

- [x] **Task 4.3: Transcript Processing Service**
  - Create service to clean and prepare video transcripts
  - Implement transcript summarization for long content
  - Extract key themes and topics from transcripts
  - **Testing**: Test with various transcript lengths and qualities

---

## 🔧 **Phase 5: Core Business Logic**

- [x] **Task 5.1: Content Generation Orchestrator**
  - Create main service to coordinate platform-specific generation
  - Add retry logic and error handling
  - **Testing**: Test orchestration with multiple platform requests

- [x] **Task 5.2: Content Validation Service**
  - Implement validation for generated content against platform rules
  - Implement fallback content generation for failed validations
  - **Testing**: Test validation with edge cases and invalid content
---

## 🌐 **Phase 6: API Endpoints**

- [x] **Task 6.1: Single Platform Generation Endpoint**
  - Create POST `/generate/{platform}` endpoint
  - Implement request/response models
  - Add input validation and error handling
  - **Testing**: Test endpoint with valid/invalid inputs for each platform

- [x] **Task 6.2: Platform Rules Information Endpoint**
  - Create GET `/platforms/{platform}/rules` endpoint
  - Return platform-specific constraints and guidelines
  - **Testing**: Verify correct rule information for each platform

---

## 📊 **Phase 7: Enhanced Features**

- [ ] **Task 7.1: Content Alternatives Generator**
  - Generate multiple title/tag variations per platform
  - Implement ranking system for generated alternatives
  - **Testing**: Test alternative generation quality and diversity

- [ ] **Task 7.2: Trending Keywords Integration**
  - Integrate with trending keywords APIs (optional)
  - Update platform-specific trending considerations
  - **Testing**: Test trending keyword integration and relevance

- [ ] **Task 7.3: Content Analytics Preparation**
  - Add metadata tracking for generated content
  - Implement performance prediction scoring
  - **Testing**: Test metadata collection and scoring accuracy

---

## ✅ **Phase 8: Testing & Validation**

- [ ] **Task 8.1: Unit Tests**
  - Create comprehensive unit tests for all models
  - Test all service methods independently
  - Test platform-specific rule enforcement
  - **Testing**: Achieve >90% code coverage

- [ ] **Task 8.2: Integration Tests**
  - Test end-to-end API workflows
  - Test AI service integration with various transcript types
  - Test error handling and edge cases
  - **Testing**: Validate complete user workflows

- [ ] **Task 8.3: Performance Tests**
  - Test generation speed for single/batch requests
  - Test concurrent request handling
  - Test memory usage with large transcripts
  - **Testing**: Ensure acceptable response times (<5s per platform)

---

## 📖 **Phase 9: Documentation & Deployment**

- [ ] **Task 9.1: API Documentation**
  - Generate OpenAPI/Swagger documentation
  - Create usage examples for each endpoint
  - Document platform-specific requirements
  - **Testing**: Verify documentation accuracy with actual API

- [ ] **Task 9.2: Configuration Documentation**
  - Document environment variable requirements
  - Create deployment guide
  - Document platform rule customization options
  - **Testing**: Test deployment from documentation

---

## 🎯 **Success Criteria for Each Phase**

1. **Phase 1**: API connection established, FastAPI running
2. **Phase 2**: All models validate correctly with sample data  
3. **Phase 3**: Platform rules enforced and tested
4. **Phase 4**: AI generates relevant content for each platform
5. **Phase 5**: Content meets platform requirements consistently
6. **Phase 6**: API endpoints respond correctly with valid data
7. **Phase 7**: Enhanced features improve content quality
8. **Phase 8**: All tests pass, system handles edge cases
9. **Phase 9**: System is documented and deployable

---

## 🔍 **Independent Testing Strategy**

Each task includes specific testing criteria that can be validated independently before moving to the next task. This ensures each component works correctly in isolation and integrates properly with the overall system.

---

## 📋 **Platform-Specific Requirements Summary**

| Platform | Title Length | Tag Count | Style Focus |
|----------|-------------|-----------|-------------|
| YouTube | 100 chars | 10-15 tags | Educational/Entertainment |
| Instagram | 150 chars | 20-30 hashtags | Visual-first, Lifestyle |
| Facebook | 255 chars | 3-5 hashtags | Community-building |
| TikTok | 150 chars | 3-5 hashtags | Trend-focused, Gen-Z |
| X (Twitter) | 280 chars total | 2-3 hashtags | Concise, Timely |
| LinkedIn | 210 chars | 3-5 hashtags | Professional, Thought-leadership |
| Twitch | 140 chars | Gaming tags | Gaming community |

---

## 🚀 **Getting Started**

1. Start with Phase 1 to set up the foundation
2. Complete each task in sequence within each phase
3. Run the specified tests for each task before proceeding
4. Each phase builds upon the previous one
5. Maintain independent testability for each component

---

### How to check off tasks
Replace the empty space inside the brackets with an `x` like so: `[x]`.
> Example:  
> - [x] Install dependencies

Happy hacking! 🚀

================
File: .gitignore
================
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# UV
#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#uv.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
.pdm.toml
.pdm-python
.pdm-build/

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

# Abstra
# Abstra is an AI-powered process automation framework.
# Ignore directories containing user credentials, local state, and settings.
# Learn more at https://abstra.io/docs
.abstra/

# Visual Studio Code
#  Visual Studio Code specific template is maintained in a separate VisualStudioCode.gitignore 
#  that can be found at https://github.com/github/gitignore/blob/main/Global/VisualStudioCode.gitignore
#  and can be added to the global gitignore or merged into this file. However, if you prefer, 
#  you could uncomment the following to ignore the enitre vscode folder
# .vscode/

# Ruff stuff:
.ruff_cache/

# PyPI configuration file
.pypirc

# Cursor
#  Cursor is an AI-powered code editor. `.cursorignore` specifies files/directories to
#  exclude from AI features like autocomplete and code analysis. Recommended for sensitive data
#  refer to https://docs.cursor.com/context/ignore-files
.cursorignore
.cursorindexingignore

================
File: LICENSE
================
MIT License

Copyright (c) 2025 Mayank Singh

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

================
File: README.md
================
# hack-ai-stan-backend
Python backend for Hack AI - Stan project

================
File: requirements.txt
================
annotated-types==0.7.0
anthropic==0.54.0
anyio==4.9.0
appnope==0.1.4
argcomplete==3.6.2
asttokens==3.0.0
boto3==1.38.41
botocore==1.38.41
cachetools==5.5.2
certifi==2025.6.15
charset-normalizer==3.4.2
click==8.2.1
cohere==5.15.0
colorama==0.4.6
comm==0.2.2
debugpy==1.8.14
decorator==5.2.1
distro==1.9.0
eval_type_backport==0.2.2
executing==2.2.0
fasta2a==0.3.2
fastapi==0.115.13
fastavro==1.11.1
filelock==3.18.0
fsspec==2025.5.1
google-auth==2.40.3
google-genai==1.21.1
griffe==1.7.3
groq==0.28.0
h11==0.16.0
hf-xet==1.1.5
httpcore==1.0.9
httpx==0.28.1
httpx-sse==0.4.0
huggingface-hub==0.33.0
idna==3.10
importlib_metadata==8.7.0
iniconfig==2.1.0
ipykernel==6.29.5
ipython==9.3.0
ipython_pygments_lexers==1.1.1
jedi==0.19.2
jiter==0.10.0
jmespath==1.0.1
jupyter_client==8.6.3
jupyter_core==5.8.1
logfire-api==3.21.1
markdown-it-py==3.0.0
matplotlib-inline==0.1.7
mcp==1.9.4
mdurl==0.1.2
mistralai==1.8.2
nest-asyncio==1.6.0
openai==1.90.0
opentelemetry-api==1.34.1
packaging==25.0
parso==0.8.4
pexpect==4.9.0
platformdirs==4.3.8
pluggy==1.6.0
prompt_toolkit==3.0.51
psutil==7.0.0
ptyprocess==0.7.0
pure_eval==0.2.3
pyasn1==0.6.1
pyasn1_modules==0.4.2
pydantic==2.11.7
pydantic-ai==0.3.2
pydantic-ai-slim==0.3.2
pydantic-evals==0.3.2
pydantic-graph==0.3.2
pydantic-settings==2.10.0
pydantic_core==2.33.2
Pygments==2.19.2
pytest==8.4.1
python-dateutil==2.9.0.post0
python-dotenv==1.1.0
python-multipart==0.0.20
PyYAML==6.0.2
pyzmq==27.0.0
requests==2.32.4
rich==14.0.0
rsa==4.9.1
s3transfer==0.13.0
six==1.17.0
sniffio==1.3.1
sse-starlette==2.3.6
stack-data==0.6.3
starlette==0.46.2
tenacity==8.5.0
tokenizers==0.21.1
tornado==6.5.1
tqdm==4.67.1
traitlets==5.14.3
types-requests==2.32.4.20250611
typing-inspection==0.4.1
typing_extensions==4.14.0
urllib3==2.5.0
uvicorn==0.34.3
wcwidth==0.2.13
websockets==15.0.1
zipp==3.23.0



================================================================
End of Codebase
================================================================
